{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:01:33.484381Z",
     "start_time": "2019-02-10T15:01:33.481061Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#TEMPORARILY SUPPRESS WARNINGS\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the actual labels in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:02:49.241219Z",
     "start_time": "2019-02-10T15:02:47.586565Z"
    }
   },
   "outputs": [],
   "source": [
    "captions_train_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/captions_train2017.json\"\n",
    "captions_val_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/captions_val2017.json\"\n",
    "#captions_train  = json.loads(open(captions_train_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:30:21.837928Z",
     "start_time": "2019-02-10T15:29:52.465683Z"
    }
   },
   "outputs": [],
   "source": [
    "inst_train_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_train2017.json\"\n",
    "inst_val_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_val2017.json\"\n",
    "#inst_train  = json.loads(open(inst_train_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electronics_info(captions_path, inst_path):\n",
    "    captions  = json.loads(open(captions_path).read())\n",
    "    inst  = json.loads(open(inst_path).read())\n",
    "    image_df = pd.DataFrame(inst['images'])\n",
    "    annotation_df = pd.DataFrame(inst['annotations'])\n",
    "    #the 'id' in image_df needs to be changed to 'image_id' in order to join with annotations_df\n",
    "    renamed_image_df = image_df.copy(deep=True)\n",
    "    renamed_image_df.rename(columns={'id':'image_id'}, inplace=True)\n",
    "    images_and_annotations_df = annotation_df.merge(renamed_image_df,on='image_id', how='left')\n",
    "    electronics_only_merged_df = images_and_annotations_df.loc[(images_and_annotations_df['category_id'] >= 72) & (images_and_annotations_df['category_id'] <= 77)]\n",
    "    \n",
    "    #select all images that contain electronics\n",
    "    #all_images_with_electronics = list(pd.Series(electronics_only_merged_df['image_id']).unique())\n",
    "    \n",
    "    return(electronics_only_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_electronics = get_electronics_info(captions_train_path, inst_train_path)\n",
    "val_electronics = get_electronics_info(captions_val_path, inst_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#val_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract electronics IDs in each image\n",
    "eIDs_in_images = val_electronics.groupby('image_id')['category_id'].apply(list).to_dict()\n",
    "#select all images that contain electronics\n",
    "train_images_with_electronics = list(pd.Series(train_electronics['image_id']).unique())\n",
    "val_images_with_electronics = list(pd.Series(val_electronics['image_id']).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_images_with_electronics[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_images_with_electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the validation images with electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder_name = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "all_val_filenames = os.listdir(val_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_file_id_length = len(all_val_filenames[0]) - 4#subtract 4 for the '.jpg' suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_open = []\n",
    "for image_id in val_images_with_electronics:\n",
    "    file_id = str(image_id)\n",
    "    zeros_to_add = max_file_id_length-len(file_id)\n",
    "    filename = ('0'*zeros_to_add) + file_id + '.jpg'\n",
    "    files_to_open.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_to_open[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#coco_metric.reset()\n",
    "\n",
    "#results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_2/'\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open#[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "#baseline_model = baseline.BaselineClassifier(model='faster_rcnn_resnet101_v1d_coco')\n",
    "baseline_model = baseline.BaselineClassifier(model='yolo3_darknet53_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "    #image_id = int(image[:-4])\n",
    "    #labels = val_electronics[val_electronics['image_id']==image_id]\n",
    "    #gt_bboxes = np.array([[coord for coord in entry] for entry in labels['bbox']]).reshape(1,len(labels),4)\n",
    "    ##gt_bboxes = np.array(labels['bbox'].apply(np.array))\n",
    "    #gt_labels = np.array([entry for entry in labels['category_id']]).reshape(1,len(labels))\n",
    "    ##gt_labels = np.array(labels['category_id'].apply(np.array))\n",
    "    \n",
    "    #map_object.update(bounding_boxes, class_ids.reshape(1,100), scores.reshape(1,100), gt_bboxes, gt_labels)\n",
    "    #coco_metric.update(bounding_boxes, class_ids, scores)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_object.get()\n",
    "#coco_metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841.0118069648743"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>scores</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927936</td>\n",
       "      <td>70.859024</td>\n",
       "      <td>81.128845</td>\n",
       "      <td>162.252640</td>\n",
       "      <td>329.081268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>376.342072</td>\n",
       "      <td>282.334595</td>\n",
       "      <td>660.263550</td>\n",
       "      <td>518.431458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.356848</td>\n",
       "      <td>376.498962</td>\n",
       "      <td>289.023132</td>\n",
       "      <td>657.539246</td>\n",
       "      <td>509.743530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.326432</td>\n",
       "      <td>194.305130</td>\n",
       "      <td>31.842560</td>\n",
       "      <td>372.927612</td>\n",
       "      <td>205.119370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.145672</td>\n",
       "      <td>194.305130</td>\n",
       "      <td>31.842560</td>\n",
       "      <td>372.927612</td>\n",
       "      <td>205.119370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  class_id    scores           1           2           3  \\\n",
       "0  000000464476       0.0  0.927936   70.859024   81.128845  162.252640   \n",
       "1  000000464476      63.0  0.692063  376.342072  282.334595  660.263550   \n",
       "2  000000464476      62.0  0.356848  376.498962  289.023132  657.539246   \n",
       "3  000000464476       7.0  0.326432  194.305130   31.842560  372.927612   \n",
       "4  000000464476       6.0  0.145672  194.305130   31.842560  372.927612   \n",
       "\n",
       "            4  \n",
       "0  329.081268  \n",
       "1  518.431458  \n",
       "2  509.743530  \n",
       "3  205.119370  \n",
       "4  205.119370  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_test_annotations.to_csv('val_result_annotations_2.csv')\n",
    "all_test_annotations.to_csv('val_result_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = []#[0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies_by_class = []\n",
    "num_labels_detected = []\n",
    "num_labels = []\n",
    "unique_labels_by_image = []\n",
    "unique_preds_by_image = []\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    current_unique_preds = [0, 0, 0, 0, 0, 0]\n",
    "    current_unique_labels = [0, 0, 0, 0, 0, 0]\n",
    "    pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "    label_counts = [0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    unique_label_count = len(unique_labels)\n",
    "    unique_labels_detected = 0\n",
    "    for label in unique_labels:\n",
    "        #label_counts[label-72] += 1\n",
    "        current_unique_labels[label-72] += 1\n",
    "        if label in unique_preds:\n",
    "            unique_labels_detected += 1\n",
    "    for pred in unique_preds:\n",
    "        #pred_counts[pred-72] += 1\n",
    "        current_unique_preds[pred-72] += 1\n",
    "    \n",
    "    #new method: count instances of each id to take FP into account\n",
    "    \n",
    "    #new method: tally accuracy for each image separately\n",
    "    \n",
    "    #store counts of each label and pred for each image\n",
    "    total_pred_counts.append(pred_counts)\n",
    "    total_label_counts.append(label_counts)\n",
    "    \n",
    "    #store unique labels and preds\n",
    "    unique_labels_by_image.append(current_unique_labels)\n",
    "    unique_preds_by_image.append(current_unique_preds)\n",
    "    \n",
    "    #counts of unique labels and preds\n",
    "    num_labels.append(unique_label_count)\n",
    "    num_labels_detected.append(unique_labels_detected)\n",
    "    \n",
    "    #detection_accuracies.append(num_labels_detected/num_labels)\n",
    "    #detection_accuracies_by_class.append(list(np.divide(current_pred_counts, current_label_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.DataFrame(total_pred_counts)\n",
    "label_counts = pd.DataFrame(total_label_counts)\n",
    "pred_counts[6] = pred_counts.sum(axis=1)\n",
    "label_counts[6] = label_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6\n",
       "0  2  0  0  0  0  0  2\n",
       "1  0  0  0  0  0  1  1\n",
       "2  0  0  0  0  0  1  1\n",
       "3  1  1  2  0  1  0  5\n",
       "4  0  0  0  0  1  0  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.431579\n",
       "1    0.366071\n",
       "2    0.314286\n",
       "3    0.709091\n",
       "4    0.543624\n",
       "5    0.630522\n",
       "6    0.476301\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = label_counts.subtract(pred_counts).abs()\n",
    "error_rate_by_class = errors.sum(axis=0).divide(label_counts.sum(axis=0))\n",
    "error_rate_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.divide(num_labels_detected, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5712962962962963"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average percentage of unique electronics labels identified in a picture\n",
    "np.mean(np.divide(num_labels_detected, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = len(num_labels)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    141\n",
       "1    124\n",
       "2     65\n",
       "3     68\n",
       "4     66\n",
       "5     88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which of the unique labels were predicted?\n",
    "unique_labels_detected = (pd.DataFrame(unique_labels_by_image).astype(bool) & pd.DataFrame(unique_preds_by_image).astype(bool)).multiply(1).astype(int)\n",
    "unique_labels_detected.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204\n",
       "1    176\n",
       "2     87\n",
       "3    138\n",
       "4    103\n",
       "5    205\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_labeled = pd.DataFrame(unique_labels_by_image).sum(axis=0)\n",
    "num_images_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046002190580504"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall rate of detecting that a label is present\n",
    "unique_labels_detected.sum(axis=0).sum()/num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.691176\n",
       "1    0.704545\n",
       "2    0.747126\n",
       "3    0.492754\n",
       "4    0.640777\n",
       "5    0.429268\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each class, what fraction of images containing that class are predicted to contain that class?\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176078294692929"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average rate of detecting presence of a label, by class\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142\n",
       "1    128\n",
       "2     68\n",
       "3     77\n",
       "4     70\n",
       "5     95\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_detected = pd.DataFrame(unique_preds_by_image).sum(axis=0)\n",
    "num_images_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.696078\n",
       "1    0.727273\n",
       "2    0.781609\n",
       "3    0.557971\n",
       "4    0.679612\n",
       "5    0.463415\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(num_images_detected, num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#coco_metric.reset()\n",
    "\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_2/'\n",
    "#results_folder = '/mnt/muthderd/MIDS/W210/data/val_results/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open#[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "baseline_model = baseline.BaselineClassifier(model='faster_rcnn_resnet101_v1d_coco')\n",
    "#baseline_model = baseline.BaselineClassifier(model='yolo3_darknet53_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "    #image_id = int(image[:-4])\n",
    "    #labels = val_electronics[val_electronics['image_id']==image_id]\n",
    "    #gt_bboxes = np.array([[coord for coord in entry] for entry in labels['bbox']]).reshape(1,len(labels),4)\n",
    "    ##gt_bboxes = np.array(labels['bbox'].apply(np.array))\n",
    "    #gt_labels = np.array([entry for entry in labels['category_id']]).reshape(1,len(labels))\n",
    "    ##gt_labels = np.array(labels['category_id'].apply(np.array))\n",
    "    \n",
    "    #map_object.update(bounding_boxes, class_ids.reshape(1,100), scores.reshape(1,100), gt_bboxes, gt_labels)\n",
    "    #coco_metric.update(bounding_boxes, class_ids, scores)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_annotations.to_csv('val_result_annotations_2.csv')\n",
    "#all_test_annotations.to_csv('val_result_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = []#[0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies_by_class = []\n",
    "num_labels_detected = []\n",
    "num_labels = []\n",
    "unique_labels_by_image = []\n",
    "unique_preds_by_image = []\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    current_unique_preds = [0, 0, 0, 0, 0, 0]\n",
    "    current_unique_labels = [0, 0, 0, 0, 0, 0]\n",
    "    pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "    label_counts = [0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    unique_label_count = len(unique_labels)\n",
    "    unique_labels_detected = 0\n",
    "    for label in unique_labels:\n",
    "        #label_counts[label-72] += 1\n",
    "        current_unique_labels[label-72] += 1\n",
    "        if label in unique_preds:\n",
    "            unique_labels_detected += 1\n",
    "    for pred in unique_preds:\n",
    "        #pred_counts[pred-72] += 1\n",
    "        current_unique_preds[pred-72] += 1\n",
    "    \n",
    "    #new method: count instances of each id to take FP into account\n",
    "    \n",
    "    #new method: tally accuracy for each image separately\n",
    "    \n",
    "    #store counts of each label and pred for each image\n",
    "    total_pred_counts.append(pred_counts)\n",
    "    total_label_counts.append(label_counts)\n",
    "    \n",
    "    #store unique labels and preds\n",
    "    unique_labels_by_image.append(current_unique_labels)\n",
    "    unique_preds_by_image.append(current_unique_preds)\n",
    "    \n",
    "    #counts of unique labels and preds\n",
    "    num_labels.append(unique_label_count)\n",
    "    num_labels_detected.append(unique_labels_detected)\n",
    "    \n",
    "    #detection_accuracies.append(num_labels_detected/num_labels)\n",
    "    #detection_accuracies_by_class.append(list(np.divide(current_pred_counts, current_label_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.DataFrame(total_pred_counts)\n",
    "label_counts = pd.DataFrame(total_label_counts)\n",
    "pred_counts[6] = pred_counts.sum(axis=1)\n",
    "label_counts[6] = label_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = label_counts.subtract(pred_counts).abs()\n",
    "error_rate_by_class = errors.sum(axis=0).divide(label_counts.sum(axis=0))\n",
    "error_rate_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.divide(num_labels_detected, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average percentage of unique electronics labels identified in a picture\n",
    "np.mean(np.divide(num_labels_detected, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(num_labels)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which of the unique labels were predicted?\n",
    "unique_labels_detected = (pd.DataFrame(unique_labels_by_image).astype(bool) & pd.DataFrame(unique_preds_by_image).astype(bool)).multiply(1).astype(int)\n",
    "unique_labels_detected.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_labeled = pd.DataFrame(unique_labels_by_image).sum(axis=0)\n",
    "num_images_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall rate of detecting that a label is present\n",
    "unique_labels_detected.sum(axis=0).sum()/num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each class, what fraction of images containing that class are predicted to contain that class?\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rate of detecting presence of a label, by class\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_detected = pd.DataFrame(unique_preds_by_image).sum(axis=0)\n",
    "num_images_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide(num_images_detected, num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_3/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open#[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "baseline_model = baseline.BaselineClassifier(model='ssd_512_resnet50_v1_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_annotations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_annotations.to_csv('val_result_annotations_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = []#[0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies_by_class = []\n",
    "num_labels_detected = []\n",
    "num_labels = []\n",
    "unique_labels_by_image = []\n",
    "unique_preds_by_image = []\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    current_unique_preds = [0, 0, 0, 0, 0, 0]\n",
    "    current_unique_labels = [0, 0, 0, 0, 0, 0]\n",
    "    pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "    label_counts = [0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    unique_label_count = len(unique_labels)\n",
    "    unique_labels_detected = 0\n",
    "    for label in unique_labels:\n",
    "        #label_counts[label-72] += 1\n",
    "        current_unique_labels[label-72] += 1\n",
    "        if label in unique_preds:\n",
    "            unique_labels_detected += 1\n",
    "    for pred in unique_preds:\n",
    "        #pred_counts[pred-72] += 1\n",
    "        current_unique_preds[pred-72] += 1\n",
    "    \n",
    "    #new method: count instances of each id to take FP into account\n",
    "    \n",
    "    #new method: tally accuracy for each image separately\n",
    "    \n",
    "    #store counts of each label and pred for each image\n",
    "    total_pred_counts.append(pred_counts)\n",
    "    total_label_counts.append(label_counts)\n",
    "    \n",
    "    #store unique labels and preds\n",
    "    unique_labels_by_image.append(current_unique_labels)\n",
    "    unique_preds_by_image.append(current_unique_preds)\n",
    "    \n",
    "    #counts of unique labels and preds\n",
    "    num_labels.append(unique_label_count)\n",
    "    num_labels_detected.append(unique_labels_detected)\n",
    "    \n",
    "    #detection_accuracies.append(num_labels_detected/num_labels)\n",
    "    #detection_accuracies_by_class.append(list(np.divide(current_pred_counts, current_label_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.DataFrame(total_pred_counts)\n",
    "label_counts = pd.DataFrame(total_label_counts)\n",
    "pred_counts[6] = pred_counts.sum(axis=1)\n",
    "label_counts[6] = label_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = label_counts.subtract(pred_counts).abs()\n",
    "error_rate_by_class = errors.sum(axis=0).divide(label_counts.sum(axis=0))\n",
    "error_rate_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.divide(num_labels_detected, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average percentage of unique electronics labels identified in a picture\n",
    "np.mean(np.divide(num_labels_detected, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(num_labels)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which of the unique labels were predicted?\n",
    "unique_labels_detected = (pd.DataFrame(unique_labels_by_image).astype(bool) & pd.DataFrame(unique_preds_by_image).astype(bool)).multiply(1).astype(int)\n",
    "unique_labels_detected.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_labeled = pd.DataFrame(unique_labels_by_image).sum(axis=0)\n",
    "num_images_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall rate of detecting that a label is present\n",
    "unique_labels_detected.sum(axis=0).sum()/num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each class, what fraction of images containing that class are predicted to contain that class?\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average rate of detecting presence of a label, by class\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_detected = pd.DataFrame(unique_preds_by_image).sum(axis=0)\n",
    "num_images_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide(num_images_detected, num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
