{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:01:33.484381Z",
     "start_time": "2019-02-10T15:01:33.481061Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#TEMPORARILY SUPPRESS WARNINGS\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the actual labels in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:02:49.241219Z",
     "start_time": "2019-02-10T15:02:47.586565Z"
    }
   },
   "outputs": [],
   "source": [
    "captions_train_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/captions_train2017.json\"\n",
    "captions_val_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/captions_val2017.json\"\n",
    "#captions_train  = json.loads(open(captions_train_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:30:21.837928Z",
     "start_time": "2019-02-10T15:29:52.465683Z"
    }
   },
   "outputs": [],
   "source": [
    "inst_train_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_train2017.json\"\n",
    "inst_val_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_val2017.json\"\n",
    "#inst_train  = json.loads(open(inst_train_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electronics_info(captions_path, inst_path):\n",
    "    captions  = json.loads(open(captions_path).read())\n",
    "    inst  = json.loads(open(inst_path).read())\n",
    "    image_df = pd.DataFrame(inst['images'])\n",
    "    annotation_df = pd.DataFrame(inst['annotations'])\n",
    "    #the 'id' in image_df needs to be changed to 'image_id' in order to join with annotations_df\n",
    "    renamed_image_df = image_df.copy(deep=True)\n",
    "    renamed_image_df.rename(columns={'id':'image_id'}, inplace=True)\n",
    "    images_and_annotations_df = annotation_df.merge(renamed_image_df,on='image_id', how='left')\n",
    "    electronics_only_merged_df = images_and_annotations_df.loc[(images_and_annotations_df['category_id'] >= 72) & (images_and_annotations_df['category_id'] <= 77)]\n",
    "    \n",
    "    #select all images that contain electronics\n",
    "    #all_images_with_electronics = list(pd.Series(electronics_only_merged_df['image_id']).unique())\n",
    "    \n",
    "    return(electronics_only_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_electronics = get_electronics_info(captions_train_path, inst_train_path)\n",
    "val_electronics = get_electronics_info(captions_val_path, inst_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#val_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>coco_url</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flickr_url</th>\n",
       "      <th>height</th>\n",
       "      <th>license</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24452</th>\n",
       "      <td>13244.65770</td>\n",
       "      <td>[7.03, 167.76, 149.32, 94.87]</td>\n",
       "      <td>72</td>\n",
       "      <td>34646</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>[[9.66, 167.76, 156.35, 173.04, 153.71, 256.48...</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000000...</td>\n",
       "      <td>2013-11-21 01:34:01</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>http://farm9.staticflickr.com/8035/8024364858_...</td>\n",
       "      <td>426</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24458</th>\n",
       "      <td>5833.11795</td>\n",
       "      <td>[557.21, 209.19, 81.35, 78.73]</td>\n",
       "      <td>72</td>\n",
       "      <td>35802</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>[[563.33, 209.19, 637.69, 209.19, 638.56, 287....</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000000...</td>\n",
       "      <td>2013-11-21 01:34:01</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>http://farm9.staticflickr.com/8035/8024364858_...</td>\n",
       "      <td>426</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area                            bbox  category_id     id  \\\n",
       "24452  13244.65770   [7.03, 167.76, 149.32, 94.87]           72  34646   \n",
       "24458   5833.11795  [557.21, 209.19, 81.35, 78.73]           72  35802   \n",
       "\n",
       "       image_id  iscrowd                                       segmentation  \\\n",
       "24452       139        0  [[9.66, 167.76, 156.35, 173.04, 153.71, 256.48...   \n",
       "24458       139        0  [[563.33, 209.19, 637.69, 209.19, 638.56, 287....   \n",
       "\n",
       "                                                coco_url        date_captured  \\\n",
       "24452  http://images.cocodataset.org/val2017/00000000...  2013-11-21 01:34:01   \n",
       "24458  http://images.cocodataset.org/val2017/00000000...  2013-11-21 01:34:01   \n",
       "\n",
       "              file_name                                         flickr_url  \\\n",
       "24452  000000000139.jpg  http://farm9.staticflickr.com/8035/8024364858_...   \n",
       "24458  000000000139.jpg  http://farm9.staticflickr.com/8035/8024364858_...   \n",
       "\n",
       "       height  license  width  \n",
       "24452     426        2    640  \n",
       "24458     426        2    640  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_electronics[val_electronics['image_id']==139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract electronics IDs in each image\n",
    "eIDs_in_images = val_electronics.groupby('image_id')['category_id'].apply(list).to_dict()\n",
    "#select all images that contain electronics\n",
    "train_images_with_electronics = list(pd.Series(train_electronics['image_id']).unique())\n",
    "val_images_with_electronics = list(pd.Series(val_electronics['image_id']).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_images_with_electronics[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_images_with_electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the validation images with electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder_name = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "all_val_filenames = os.listdir(val_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_file_id_length = len(all_val_filenames[0]) - 4#subtract 4 for the '.jpg' suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_open = []\n",
    "for image_id in val_images_with_electronics:\n",
    "    file_id = str(image_id)\n",
    "    zeros_to_add = max_file_id_length-len(file_id)\n",
    "    filename = ('0'*zeros_to_add) + file_id + '.jpg'\n",
    "    files_to_open.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_to_open[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000384670.jpg',\n",
       " '000000097988.jpg',\n",
       " '000000347693.jpg',\n",
       " '000000001490.jpg',\n",
       " '000000421455.jpg',\n",
       " '000000558114.jpg',\n",
       " '000000517056.jpg',\n",
       " '000000050828.jpg',\n",
       " '000000277584.jpg',\n",
       " '000000386879.jpg',\n",
       " '000000521717.jpg',\n",
       " '000000439773.jpg',\n",
       " '000000124442.jpg',\n",
       " '000000152870.jpg',\n",
       " '000000500716.jpg',\n",
       " '000000114770.jpg',\n",
       " '000000430286.jpg',\n",
       " '000000391144.jpg',\n",
       " '000000283070.jpg',\n",
       " '000000268000.jpg',\n",
       " '000000363188.jpg',\n",
       " '000000058111.jpg',\n",
       " '000000384850.jpg',\n",
       " '000000491470.jpg',\n",
       " '000000550714.jpg',\n",
       " '000000283318.jpg',\n",
       " '000000427055.jpg',\n",
       " '000000268375.jpg',\n",
       " '000000290592.jpg',\n",
       " '000000147223.jpg',\n",
       " '000000004395.jpg',\n",
       " '000000574810.jpg',\n",
       " '000000128112.jpg',\n",
       " '000000172877.jpg',\n",
       " '000000500257.jpg',\n",
       " '000000052007.jpg',\n",
       " '000000329456.jpg',\n",
       " '000000249219.jpg',\n",
       " '000000227187.jpg',\n",
       " '000000306437.jpg',\n",
       " '000000434230.jpg',\n",
       " '000000166768.jpg',\n",
       " '000000040471.jpg',\n",
       " '000000489611.jpg',\n",
       " '000000424521.jpg',\n",
       " '000000410456.jpg',\n",
       " '000000286422.jpg',\n",
       " '000000353970.jpg',\n",
       " '000000108026.jpg',\n",
       " '000000358525.jpg',\n",
       " '000000270297.jpg',\n",
       " '000000041990.jpg',\n",
       " '000000377497.jpg',\n",
       " '000000449603.jpg',\n",
       " '000000455624.jpg',\n",
       " '000000269632.jpg',\n",
       " '000000062554.jpg',\n",
       " '000000420230.jpg',\n",
       " '000000074256.jpg',\n",
       " '000000335658.jpg',\n",
       " '000000001425.jpg',\n",
       " '000000428454.jpg',\n",
       " '000000239627.jpg',\n",
       " '000000455085.jpg',\n",
       " '000000211825.jpg',\n",
       " '000000256518.jpg',\n",
       " '000000191672.jpg',\n",
       " '000000203629.jpg',\n",
       " '000000336209.jpg',\n",
       " '000000489046.jpg',\n",
       " '000000530061.jpg',\n",
       " '000000235399.jpg',\n",
       " '000000245311.jpg',\n",
       " '000000404923.jpg',\n",
       " '000000296222.jpg',\n",
       " '000000404568.jpg',\n",
       " '000000310072.jpg',\n",
       " '000000118921.jpg',\n",
       " '000000519039.jpg',\n",
       " '000000571264.jpg',\n",
       " '000000507797.jpg',\n",
       " '000000177065.jpg',\n",
       " '000000332845.jpg',\n",
       " '000000506656.jpg',\n",
       " '000000476215.jpg',\n",
       " '000000476415.jpg',\n",
       " '000000004495.jpg',\n",
       " '000000032901.jpg',\n",
       " '000000467176.jpg',\n",
       " '000000072852.jpg',\n",
       " '000000494759.jpg',\n",
       " '000000456143.jpg',\n",
       " '000000042628.jpg',\n",
       " '000000229553.jpg',\n",
       " '000000084270.jpg',\n",
       " '000000045728.jpg',\n",
       " '000000060363.jpg',\n",
       " '000000222559.jpg',\n",
       " '000000478136.jpg',\n",
       " '000000308531.jpg',\n",
       " '000000260261.jpg',\n",
       " '000000059386.jpg',\n",
       " '000000394559.jpg',\n",
       " '000000227898.jpg',\n",
       " '000000407650.jpg',\n",
       " '000000069138.jpg',\n",
       " '000000475387.jpg',\n",
       " '000000192047.jpg',\n",
       " '000000343149.jpg',\n",
       " '000000501243.jpg',\n",
       " '000000367228.jpg',\n",
       " '000000214539.jpg',\n",
       " '000000329447.jpg',\n",
       " '000000239773.jpg',\n",
       " '000000414673.jpg',\n",
       " '000000338325.jpg',\n",
       " '000000523100.jpg',\n",
       " '000000529568.jpg',\n",
       " '000000234366.jpg',\n",
       " '000000511321.jpg',\n",
       " '000000002592.jpg',\n",
       " '000000409867.jpg',\n",
       " '000000110721.jpg',\n",
       " '000000354753.jpg',\n",
       " '000000050326.jpg',\n",
       " '000000466986.jpg',\n",
       " '000000478286.jpg',\n",
       " '000000002149.jpg',\n",
       " '000000447611.jpg',\n",
       " '000000578545.jpg',\n",
       " '000000380706.jpg',\n",
       " '000000050380.jpg',\n",
       " '000000130465.jpg',\n",
       " '000000570456.jpg',\n",
       " '000000117525.jpg',\n",
       " '000000295316.jpg',\n",
       " '000000493799.jpg',\n",
       " '000000291634.jpg',\n",
       " '000000446651.jpg',\n",
       " '000000430875.jpg',\n",
       " '000000352618.jpg',\n",
       " '000000352900.jpg',\n",
       " '000000269113.jpg',\n",
       " '000000397327.jpg',\n",
       " '000000136033.jpg',\n",
       " '000000068078.jpg',\n",
       " '000000499109.jpg',\n",
       " '000000210789.jpg',\n",
       " '000000579070.jpg',\n",
       " '000000237118.jpg',\n",
       " '000000252507.jpg',\n",
       " '000000121417.jpg',\n",
       " '000000562818.jpg',\n",
       " '000000498709.jpg',\n",
       " '000000085329.jpg',\n",
       " '000000050165.jpg',\n",
       " '000000417465.jpg',\n",
       " '000000414795.jpg',\n",
       " '000000543043.jpg',\n",
       " '000000462643.jpg',\n",
       " '000000098520.jpg',\n",
       " '000000431545.jpg',\n",
       " '000000221693.jpg',\n",
       " '000000127530.jpg',\n",
       " '000000172595.jpg',\n",
       " '000000348481.jpg',\n",
       " '000000110638.jpg',\n",
       " '000000154718.jpg',\n",
       " '000000265816.jpg',\n",
       " '000000326542.jpg',\n",
       " '000000350019.jpg',\n",
       " '000000579307.jpg',\n",
       " '000000367095.jpg',\n",
       " '000000284725.jpg',\n",
       " '000000332455.jpg',\n",
       " '000000527784.jpg',\n",
       " '000000335081.jpg',\n",
       " '000000565877.jpg',\n",
       " '000000087038.jpg',\n",
       " '000000523033.jpg',\n",
       " '000000073702.jpg',\n",
       " '000000166287.jpg',\n",
       " '000000358427.jpg',\n",
       " '000000159458.jpg',\n",
       " '000000148662.jpg',\n",
       " '000000577149.jpg',\n",
       " '000000489091.jpg',\n",
       " '000000451693.jpg',\n",
       " '000000287527.jpg',\n",
       " '000000424776.jpg',\n",
       " '000000093353.jpg',\n",
       " '000000226111.jpg',\n",
       " '000000046497.jpg',\n",
       " '000000133645.jpg',\n",
       " '000000127517.jpg',\n",
       " '000000079229.jpg',\n",
       " '000000267946.jpg',\n",
       " '000000426376.jpg',\n",
       " '000000108864.jpg',\n",
       " '000000060449.jpg',\n",
       " '000000067180.jpg',\n",
       " '000000025603.jpg',\n",
       " '000000106912.jpg',\n",
       " '000000355905.jpg',\n",
       " '000000097585.jpg',\n",
       " '000000569030.jpg',\n",
       " '000000065736.jpg',\n",
       " '000000134322.jpg',\n",
       " '000000132116.jpg',\n",
       " '000000220858.jpg',\n",
       " '000000144984.jpg',\n",
       " '000000506279.jpg',\n",
       " '000000242060.jpg',\n",
       " '000000212800.jpg',\n",
       " '000000499266.jpg',\n",
       " '000000245320.jpg',\n",
       " '000000316404.jpg',\n",
       " '000000007386.jpg',\n",
       " '000000400044.jpg',\n",
       " '000000262048.jpg',\n",
       " '000000507081.jpg',\n",
       " '000000545730.jpg',\n",
       " '000000533536.jpg',\n",
       " '000000580197.jpg',\n",
       " '000000105014.jpg',\n",
       " '000000083113.jpg',\n",
       " '000000261116.jpg',\n",
       " '000000396338.jpg',\n",
       " '000000177539.jpg',\n",
       " '000000136466.jpg',\n",
       " '000000328117.jpg',\n",
       " '000000438907.jpg',\n",
       " '000000439525.jpg',\n",
       " '000000273715.jpg',\n",
       " '000000290771.jpg',\n",
       " '000000202445.jpg',\n",
       " '000000442009.jpg',\n",
       " '000000519208.jpg',\n",
       " '000000461275.jpg',\n",
       " '000000423519.jpg',\n",
       " '000000385997.jpg',\n",
       " '000000046378.jpg',\n",
       " '000000452515.jpg',\n",
       " '000000011511.jpg',\n",
       " '000000183709.jpg',\n",
       " '000000314541.jpg',\n",
       " '000000491725.jpg',\n",
       " '000000223182.jpg',\n",
       " '000000184321.jpg',\n",
       " '000000330554.jpg',\n",
       " '000000428280.jpg',\n",
       " '000000175387.jpg',\n",
       " '000000477227.jpg',\n",
       " '000000266082.jpg',\n",
       " '000000198510.jpg',\n",
       " '000000571893.jpg',\n",
       " '000000537355.jpg',\n",
       " '000000459153.jpg',\n",
       " '000000444879.jpg',\n",
       " '000000272136.jpg',\n",
       " '000000281754.jpg',\n",
       " '000000010583.jpg',\n",
       " '000000118209.jpg',\n",
       " '000000427500.jpg',\n",
       " '000000008021.jpg',\n",
       " '000000192670.jpg',\n",
       " '000000125936.jpg',\n",
       " '000000134096.jpg',\n",
       " '000000255401.jpg',\n",
       " '000000297595.jpg',\n",
       " '000000222863.jpg',\n",
       " '000000275198.jpg',\n",
       " '000000535306.jpg',\n",
       " '000000250901.jpg',\n",
       " '000000228144.jpg',\n",
       " '000000351589.jpg',\n",
       " '000000027696.jpg',\n",
       " '000000017031.jpg',\n",
       " '000000279145.jpg',\n",
       " '000000511453.jpg',\n",
       " '000000250205.jpg',\n",
       " '000000565624.jpg',\n",
       " '000000500663.jpg',\n",
       " '000000116208.jpg',\n",
       " '000000286849.jpg',\n",
       " '000000323828.jpg',\n",
       " '000000578967.jpg',\n",
       " '000000481582.jpg',\n",
       " '000000311002.jpg',\n",
       " '000000557884.jpg',\n",
       " '000000123480.jpg',\n",
       " '000000525155.jpg',\n",
       " '000000064495.jpg',\n",
       " '000000484893.jpg',\n",
       " '000000302990.jpg',\n",
       " '000000129113.jpg',\n",
       " '000000037751.jpg',\n",
       " '000000514508.jpg',\n",
       " '000000327605.jpg',\n",
       " '000000321118.jpg',\n",
       " '000000406611.jpg',\n",
       " '000000290833.jpg',\n",
       " '000000460683.jpg',\n",
       " '000000414170.jpg',\n",
       " '000000019221.jpg',\n",
       " '000000572555.jpg',\n",
       " '000000368335.jpg',\n",
       " '000000560911.jpg',\n",
       " '000000144798.jpg',\n",
       " '000000479912.jpg',\n",
       " '000000089880.jpg',\n",
       " '000000252559.jpg',\n",
       " '000000178028.jpg',\n",
       " '000000181859.jpg',\n",
       " '000000369370.jpg',\n",
       " '000000412286.jpg',\n",
       " '000000363875.jpg',\n",
       " '000000403565.jpg',\n",
       " '000000131938.jpg',\n",
       " '000000297085.jpg',\n",
       " '000000049091.jpg',\n",
       " '000000553776.jpg',\n",
       " '000000171757.jpg',\n",
       " '000000389451.jpg',\n",
       " '000000329827.jpg',\n",
       " '000000342128.jpg',\n",
       " '000000400803.jpg',\n",
       " '000000197796.jpg',\n",
       " '000000077595.jpg',\n",
       " '000000468501.jpg',\n",
       " '000000478862.jpg',\n",
       " '000000187362.jpg',\n",
       " '000000426297.jpg',\n",
       " '000000246968.jpg',\n",
       " '000000133233.jpg',\n",
       " '000000100582.jpg',\n",
       " '000000516804.jpg',\n",
       " '000000172977.jpg',\n",
       " '000000130699.jpg',\n",
       " '000000407083.jpg',\n",
       " '000000130586.jpg',\n",
       " '000000084674.jpg',\n",
       " '000000416104.jpg',\n",
       " '000000549738.jpg',\n",
       " '000000080274.jpg',\n",
       " '000000007888.jpg',\n",
       " '000000108495.jpg',\n",
       " '000000390555.jpg',\n",
       " '000000028285.jpg',\n",
       " '000000000802.jpg',\n",
       " '000000539143.jpg',\n",
       " '000000110884.jpg',\n",
       " '000000140439.jpg',\n",
       " '000000423944.jpg',\n",
       " '000000355677.jpg',\n",
       " '000000450439.jpg',\n",
       " '000000237316.jpg',\n",
       " '000000127263.jpg',\n",
       " '000000297681.jpg',\n",
       " '000000545958.jpg',\n",
       " '000000267940.jpg',\n",
       " '000000564336.jpg',\n",
       " '000000018575.jpg',\n",
       " '000000500464.jpg',\n",
       " '000000335177.jpg',\n",
       " '000000558421.jpg',\n",
       " '000000007511.jpg',\n",
       " '000000289417.jpg',\n",
       " '000000189698.jpg',\n",
       " '000000324158.jpg',\n",
       " '000000569825.jpg',\n",
       " '000000238039.jpg',\n",
       " '000000312421.jpg',\n",
       " '000000068409.jpg',\n",
       " '000000378139.jpg',\n",
       " '000000192607.jpg',\n",
       " '000000512648.jpg',\n",
       " '000000530854.jpg',\n",
       " '000000546826.jpg',\n",
       " '000000087875.jpg',\n",
       " '000000191761.jpg',\n",
       " '000000270883.jpg',\n",
       " '000000427649.jpg',\n",
       " '000000031248.jpg',\n",
       " '000000312552.jpg',\n",
       " '000000099810.jpg',\n",
       " '000000338428.jpg',\n",
       " '000000106281.jpg',\n",
       " '000000016249.jpg',\n",
       " '000000568690.jpg',\n",
       " '000000345356.jpg',\n",
       " '000000571943.jpg',\n",
       " '000000559348.jpg',\n",
       " '000000123131.jpg',\n",
       " '000000444142.jpg',\n",
       " '000000148783.jpg',\n",
       " '000000383384.jpg',\n",
       " '000000121497.jpg',\n",
       " '000000433134.jpg',\n",
       " '000000319534.jpg',\n",
       " '000000515025.jpg',\n",
       " '000000078426.jpg',\n",
       " '000000334483.jpg',\n",
       " '000000433915.jpg',\n",
       " '000000076211.jpg',\n",
       " '000000267434.jpg',\n",
       " '000000512657.jpg',\n",
       " '000000239843.jpg',\n",
       " '000000082715.jpg',\n",
       " '000000320490.jpg',\n",
       " '000000042102.jpg',\n",
       " '000000138639.jpg',\n",
       " '000000231097.jpg',\n",
       " '000000418062.jpg',\n",
       " '000000528578.jpg',\n",
       " '000000288042.jpg',\n",
       " '000000129812.jpg',\n",
       " '000000426241.jpg',\n",
       " '000000463174.jpg',\n",
       " '000000249180.jpg',\n",
       " '000000292155.jpg',\n",
       " '000000006723.jpg',\n",
       " '000000013546.jpg',\n",
       " '000000561223.jpg',\n",
       " '000000581482.jpg',\n",
       " '000000320642.jpg',\n",
       " '000000224664.jpg',\n",
       " '000000483999.jpg',\n",
       " '000000000139.jpg',\n",
       " '000000314034.jpg',\n",
       " '000000365098.jpg',\n",
       " '000000472678.jpg',\n",
       " '000000423971.jpg',\n",
       " '000000392722.jpg',\n",
       " '000000166259.jpg',\n",
       " '000000414385.jpg',\n",
       " '000000333697.jpg',\n",
       " '000000060102.jpg',\n",
       " '000000102820.jpg',\n",
       " '000000160772.jpg',\n",
       " '000000404922.jpg',\n",
       " '000000498747.jpg',\n",
       " '000000232088.jpg',\n",
       " '000000432898.jpg',\n",
       " '000000173371.jpg',\n",
       " '000000301061.jpg',\n",
       " '000000422670.jpg',\n",
       " '000000284279.jpg',\n",
       " '000000132408.jpg',\n",
       " '000000365642.jpg',\n",
       " '000000399560.jpg',\n",
       " '000000008844.jpg',\n",
       " '000000213445.jpg',\n",
       " '000000448365.jpg',\n",
       " '000000168883.jpg',\n",
       " '000000493442.jpg',\n",
       " '000000301867.jpg',\n",
       " '000000306700.jpg',\n",
       " '000000436551.jpg',\n",
       " '000000444275.jpg',\n",
       " '000000551820.jpg',\n",
       " '000000447522.jpg',\n",
       " '000000434479.jpg',\n",
       " '000000094185.jpg',\n",
       " '000000311295.jpg',\n",
       " '000000260657.jpg',\n",
       " '000000154004.jpg',\n",
       " '000000547519.jpg',\n",
       " '000000540280.jpg',\n",
       " '000000209753.jpg',\n",
       " '000000034873.jpg',\n",
       " '000000491130.jpg',\n",
       " '000000014831.jpg',\n",
       " '000000222118.jpg',\n",
       " '000000372577.jpg',\n",
       " '000000548555.jpg',\n",
       " '000000304560.jpg',\n",
       " '000000186938.jpg',\n",
       " '000000573258.jpg',\n",
       " '000000190753.jpg',\n",
       " '000000462629.jpg',\n",
       " '000000101420.jpg',\n",
       " '000000377575.jpg',\n",
       " '000000450202.jpg',\n",
       " '000000484415.jpg',\n",
       " '000000323709.jpg',\n",
       " '000000312213.jpg',\n",
       " '000000127660.jpg',\n",
       " '000000173033.jpg',\n",
       " '000000225670.jpg',\n",
       " '000000064084.jpg',\n",
       " '000000437205.jpg',\n",
       " '000000554595.jpg',\n",
       " '000000208363.jpg',\n",
       " '000000314709.jpg',\n",
       " '000000361142.jpg',\n",
       " '000000365766.jpg',\n",
       " '000000140640.jpg',\n",
       " '000000239537.jpg',\n",
       " '000000300842.jpg',\n",
       " '000000443844.jpg',\n",
       " '000000112298.jpg',\n",
       " '000000320554.jpg',\n",
       " '000000210388.jpg',\n",
       " '000000389933.jpg',\n",
       " '000000181816.jpg',\n",
       " '000000561679.jpg',\n",
       " '000000248616.jpg',\n",
       " '000000133969.jpg',\n",
       " '000000381587.jpg',\n",
       " '000000297830.jpg',\n",
       " '000000153782.jpg',\n",
       " '000000126107.jpg',\n",
       " '000000098839.jpg',\n",
       " '000000404128.jpg',\n",
       " '000000134112.jpg',\n",
       " '000000523241.jpg',\n",
       " '000000505565.jpg',\n",
       " '000000430056.jpg',\n",
       " '000000099114.jpg',\n",
       " '000000209972.jpg',\n",
       " '000000398905.jpg',\n",
       " '000000218424.jpg',\n",
       " '000000001353.jpg',\n",
       " '000000279774.jpg',\n",
       " '000000165713.jpg',\n",
       " '000000429530.jpg',\n",
       " '000000432085.jpg',\n",
       " '000000405970.jpg',\n",
       " '000000125211.jpg',\n",
       " '000000079188.jpg',\n",
       " '000000031269.jpg',\n",
       " '000000322968.jpg',\n",
       " '000000338905.jpg',\n",
       " '000000303566.jpg',\n",
       " '000000027620.jpg',\n",
       " '000000409358.jpg',\n",
       " '000000206994.jpg',\n",
       " '000000318238.jpg',\n",
       " '000000462614.jpg',\n",
       " '000000259830.jpg',\n",
       " '000000494869.jpg',\n",
       " '000000536343.jpg',\n",
       " '000000493613.jpg',\n",
       " '000000323151.jpg',\n",
       " '000000257169.jpg',\n",
       " '000000579635.jpg',\n",
       " '000000217285.jpg',\n",
       " '000000541123.jpg',\n",
       " '000000085772.jpg',\n",
       " '000000359855.jpg',\n",
       " '000000257566.jpg',\n",
       " '000000430048.jpg',\n",
       " '000000499181.jpg',\n",
       " '000000532530.jpg',\n",
       " '000000281032.jpg',\n",
       " '000000039484.jpg',\n",
       " '000000083540.jpg',\n",
       " '000000491090.jpg',\n",
       " '000000546556.jpg',\n",
       " '000000015751.jpg',\n",
       " '000000173057.jpg',\n",
       " '000000009769.jpg',\n",
       " '000000408696.jpg',\n",
       " '000000374369.jpg',\n",
       " '000000006763.jpg',\n",
       " '000000138954.jpg',\n",
       " '000000088345.jpg',\n",
       " '000000581615.jpg',\n",
       " '000000557172.jpg',\n",
       " '000000100510.jpg',\n",
       " '000000097278.jpg',\n",
       " '000000027768.jpg',\n",
       " '000000329455.jpg',\n",
       " '000000463522.jpg',\n",
       " '000000429623.jpg',\n",
       " '000000357567.jpg',\n",
       " '000000025181.jpg',\n",
       " '000000109916.jpg',\n",
       " '000000562197.jpg',\n",
       " '000000481390.jpg',\n",
       " '000000569700.jpg',\n",
       " '000000503755.jpg',\n",
       " '000000425702.jpg',\n",
       " '000000446117.jpg',\n",
       " '000000329041.jpg',\n",
       " '000000053909.jpg',\n",
       " '000000497628.jpg',\n",
       " '000000187243.jpg',\n",
       " '000000378453.jpg',\n",
       " '000000309964.jpg',\n",
       " '000000196185.jpg',\n",
       " '000000418281.jpg',\n",
       " '000000233033.jpg',\n",
       " '000000298904.jpg',\n",
       " '000000498807.jpg',\n",
       " '000000411754.jpg',\n",
       " '000000232684.jpg',\n",
       " '000000371529.jpg',\n",
       " '000000026204.jpg',\n",
       " '000000547144.jpg',\n",
       " '000000163562.jpg',\n",
       " '000000237984.jpg',\n",
       " '000000507235.jpg',\n",
       " '000000106048.jpg',\n",
       " '000000161032.jpg',\n",
       " '000000166277.jpg',\n",
       " '000000292997.jpg',\n",
       " '000000254516.jpg',\n",
       " '000000138979.jpg',\n",
       " '000000474078.jpg',\n",
       " '000000441586.jpg',\n",
       " '000000471087.jpg',\n",
       " '000000360960.jpg',\n",
       " '000000476704.jpg',\n",
       " '000000458410.jpg',\n",
       " '000000492077.jpg',\n",
       " '000000057238.jpg',\n",
       " '000000558854.jpg',\n",
       " '000000564133.jpg',\n",
       " '000000164115.jpg',\n",
       " '000000170739.jpg',\n",
       " '000000573094.jpg',\n",
       " '000000102411.jpg',\n",
       " '000000231125.jpg',\n",
       " '000000119911.jpg',\n",
       " '000000544519.jpg',\n",
       " '000000200839.jpg',\n",
       " '000000562581.jpg',\n",
       " '000000415727.jpg',\n",
       " '000000021839.jpg',\n",
       " '000000403817.jpg',\n",
       " '000000368752.jpg',\n",
       " '000000088265.jpg',\n",
       " '000000359677.jpg',\n",
       " '000000360325.jpg',\n",
       " '000000021167.jpg',\n",
       " '000000156071.jpg',\n",
       " '000000168330.jpg',\n",
       " '000000464089.jpg',\n",
       " '000000439994.jpg',\n",
       " '000000226130.jpg',\n",
       " '000000290248.jpg',\n",
       " '000000469652.jpg',\n",
       " '000000393056.jpg',\n",
       " '000000272212.jpg',\n",
       " '000000203294.jpg',\n",
       " '000000566758.jpg',\n",
       " '000000254368.jpg',\n",
       " '000000006614.jpg',\n",
       " '000000193245.jpg',\n",
       " '000000383838.jpg',\n",
       " '000000044279.jpg',\n",
       " '000000468233.jpg',\n",
       " '000000402765.jpg',\n",
       " '000000226903.jpg',\n",
       " '000000563604.jpg',\n",
       " '000000481159.jpg',\n",
       " '000000459809.jpg',\n",
       " '000000488385.jpg',\n",
       " '000000423798.jpg',\n",
       " '000000111207.jpg',\n",
       " '000000350388.jpg',\n",
       " '000000394199.jpg',\n",
       " '000000569273.jpg',\n",
       " '000000429109.jpg',\n",
       " '000000155291.jpg',\n",
       " '000000071877.jpg',\n",
       " '000000551815.jpg',\n",
       " '000000522638.jpg',\n",
       " '000000058636.jpg',\n",
       " '000000183716.jpg',\n",
       " '000000226662.jpg',\n",
       " '000000435081.jpg',\n",
       " '000000128051.jpg',\n",
       " '000000151662.jpg',\n",
       " '000000365387.jpg',\n",
       " '000000360661.jpg',\n",
       " '000000109441.jpg',\n",
       " '000000263644.jpg',\n",
       " '000000159399.jpg',\n",
       " '000000356261.jpg',\n",
       " '000000059920.jpg',\n",
       " '000000159282.jpg',\n",
       " '000000283037.jpg',\n",
       " '000000571857.jpg',\n",
       " '000000231339.jpg',\n",
       " '000000361238.jpg',\n",
       " '000000013291.jpg',\n",
       " '000000423229.jpg',\n",
       " '000000072813.jpg',\n",
       " '000000510095.jpg',\n",
       " '000000064868.jpg',\n",
       " '000000089648.jpg',\n",
       " '000000063965.jpg',\n",
       " '000000333745.jpg',\n",
       " '000000480021.jpg',\n",
       " '000000437392.jpg',\n",
       " '000000087244.jpg',\n",
       " '000000226147.jpg',\n",
       " '000000198641.jpg',\n",
       " '000000465675.jpg',\n",
       " '000000325306.jpg',\n",
       " '000000015440.jpg',\n",
       " '000000074092.jpg',\n",
       " '000000008690.jpg',\n",
       " '000000425906.jpg',\n",
       " '000000047801.jpg',\n",
       " '000000319607.jpg',\n",
       " '000000107851.jpg',\n",
       " '000000208208.jpg',\n",
       " '000000269942.jpg',\n",
       " '000000242724.jpg',\n",
       " '000000398377.jpg',\n",
       " '000000384350.jpg',\n",
       " '000000257084.jpg',\n",
       " '000000084650.jpg',\n",
       " '000000163257.jpg',\n",
       " '000000464522.jpg',\n",
       " '000000430973.jpg',\n",
       " '000000045090.jpg',\n",
       " '000000269316.jpg',\n",
       " '000000294163.jpg',\n",
       " '000000459887.jpg',\n",
       " '000000378873.jpg',\n",
       " '000000142472.jpg',\n",
       " '000000090631.jpg',\n",
       " '000000145591.jpg',\n",
       " '000000565469.jpg',\n",
       " '000000322211.jpg',\n",
       " '000000267300.jpg',\n",
       " '000000156292.jpg',\n",
       " '000000160666.jpg',\n",
       " '000000157138.jpg',\n",
       " '000000374727.jpg',\n",
       " '000000015956.jpg',\n",
       " '000000018770.jpg',\n",
       " '000000331280.jpg',\n",
       " '000000181796.jpg',\n",
       " '000000540466.jpg',\n",
       " '000000004765.jpg',\n",
       " '000000188906.jpg',\n",
       " '000000062355.jpg',\n",
       " '000000249129.jpg',\n",
       " '000000307145.jpg',\n",
       " '000000007784.jpg',\n",
       " '000000046463.jpg',\n",
       " '000000508586.jpg',\n",
       " '000000341719.jpg',\n",
       " '000000183049.jpg',\n",
       " '000000520301.jpg',\n",
       " '000000449909.jpg',\n",
       " '000000049259.jpg',\n",
       " '000000167240.jpg',\n",
       " '000000165039.jpg',\n",
       " '000000506707.jpg',\n",
       " '000000157098.jpg',\n",
       " '000000288430.jpg',\n",
       " '000000488673.jpg',\n",
       " '000000552371.jpg',\n",
       " '000000379800.jpg',\n",
       " '000000229111.jpg',\n",
       " '000000560256.jpg',\n",
       " '000000006471.jpg',\n",
       " '000000201072.jpg',\n",
       " '000000546964.jpg',\n",
       " '000000375278.jpg',\n",
       " '000000286660.jpg',\n",
       " '000000210230.jpg',\n",
       " '000000279769.jpg',\n",
       " '000000320232.jpg',\n",
       " '000000276024.jpg',\n",
       " '000000218362.jpg',\n",
       " '000000419408.jpg',\n",
       " '000000485844.jpg',\n",
       " '000000263425.jpg',\n",
       " '000000076261.jpg',\n",
       " '000000088040.jpg',\n",
       " '000000232646.jpg',\n",
       " '000000292005.jpg',\n",
       " '000000184762.jpg',\n",
       " '000000161861.jpg',\n",
       " '000000459757.jpg',\n",
       " '000000491071.jpg',\n",
       " '000000350002.jpg',\n",
       " '000000125245.jpg',\n",
       " '000000028449.jpg',\n",
       " '000000052412.jpg',\n",
       " '000000308545.jpg',\n",
       " '000000473869.jpg',\n",
       " '000000177213.jpg',\n",
       " '000000286708.jpg',\n",
       " '000000205542.jpg',\n",
       " '000000476258.jpg',\n",
       " '000000507223.jpg',\n",
       " '000000521141.jpg',\n",
       " '000000172396.jpg',\n",
       " '000000578236.jpg',\n",
       " '000000045229.jpg',\n",
       " '000000468332.jpg',\n",
       " '000000491216.jpg',\n",
       " '000000187734.jpg',\n",
       " '000000344268.jpg',\n",
       " '000000289059.jpg',\n",
       " '000000288391.jpg',\n",
       " '000000243344.jpg',\n",
       " '000000357430.jpg',\n",
       " '000000156076.jpg',\n",
       " '000000139077.jpg',\n",
       " '000000329323.jpg',\n",
       " '000000180011.jpg',\n",
       " '000000412887.jpg',\n",
       " '000000525286.jpg',\n",
       " '000000416343.jpg',\n",
       " '000000334309.jpg',\n",
       " '000000403122.jpg',\n",
       " '000000514797.jpg',\n",
       " '000000540414.jpg',\n",
       " '000000367082.jpg',\n",
       " '000000380711.jpg',\n",
       " '000000573943.jpg',\n",
       " '000000184611.jpg',\n",
       " '000000516708.jpg',\n",
       " '000000289516.jpg',\n",
       " '000000107339.jpg',\n",
       " '000000039956.jpg',\n",
       " '000000255912.jpg',\n",
       " '000000231508.jpg',\n",
       " '000000451435.jpg',\n",
       " '000000243626.jpg',\n",
       " '000000060855.jpg',\n",
       " '000000222235.jpg',\n",
       " '000000181666.jpg',\n",
       " '000000174371.jpg',\n",
       " '000000459272.jpg',\n",
       " '000000245026.jpg',\n",
       " '000000400082.jpg',\n",
       " '000000169076.jpg',\n",
       " '000000425925.jpg',\n",
       " '000000570539.jpg',\n",
       " '000000009914.jpg',\n",
       " '000000457848.jpg',\n",
       " '000000125572.jpg',\n",
       " '000000140076.jpg',\n",
       " '000000035963.jpg',\n",
       " '000000374083.jpg',\n",
       " '000000464786.jpg',\n",
       " '000000482436.jpg',\n",
       " '000000328238.jpg',\n",
       " '000000474170.jpg',\n",
       " '000000492362.jpg',\n",
       " '000000523229.jpg',\n",
       " '000000263969.jpg',\n",
       " '000000185250.jpg',\n",
       " '000000045472.jpg',\n",
       " '000000488251.jpg',\n",
       " '000000245102.jpg',\n",
       " '000000273493.jpg',\n",
       " '000000545100.jpg',\n",
       " '000000374551.jpg',\n",
       " '000000445999.jpg',\n",
       " '000000455716.jpg',\n",
       " '000000380913.jpg',\n",
       " '000000022755.jpg',\n",
       " '000000468925.jpg',\n",
       " '000000300659.jpg',\n",
       " '000000504074.jpg',\n",
       " '000000248334.jpg',\n",
       " '000000529105.jpg',\n",
       " '000000408112.jpg',\n",
       " '000000139872.jpg',\n",
       " '000000022589.jpg',\n",
       " '000000164885.jpg',\n",
       " '000000383621.jpg',\n",
       " '000000441543.jpg',\n",
       " '000000482585.jpg',\n",
       " '000000398203.jpg',\n",
       " '000000328683.jpg',\n",
       " '000000394940.jpg',\n",
       " '000000578871.jpg',\n",
       " '000000282296.jpg',\n",
       " '000000437351.jpg',\n",
       " '000000523957.jpg',\n",
       " '000000335328.jpg',\n",
       " '000000275727.jpg',\n",
       " '000000236412.jpg',\n",
       " '000000295809.jpg',\n",
       " '000000187745.jpg',\n",
       " '000000066817.jpg',\n",
       " '000000567825.jpg',\n",
       " '000000261061.jpg',\n",
       " '000000242411.jpg',\n",
       " '000000162035.jpg',\n",
       " '000000007108.jpg',\n",
       " '000000232538.jpg',\n",
       " '000000245764.jpg',\n",
       " '000000545007.jpg',\n",
       " '000000520009.jpg',\n",
       " '000000291791.jpg',\n",
       " '000000531036.jpg',\n",
       " '000000568710.jpg',\n",
       " '000000571598.jpg',\n",
       " '000000258388.jpg',\n",
       " '000000133343.jpg',\n",
       " '000000172083.jpg',\n",
       " '000000166521.jpg',\n",
       " '000000292415.jpg',\n",
       " '000000445834.jpg',\n",
       " '000000409211.jpg',\n",
       " '000000211042.jpg',\n",
       " '000000565391.jpg',\n",
       " '000000274708.jpg',\n",
       " '000000460333.jpg',\n",
       " '000000131138.jpg',\n",
       " '000000264535.jpg',\n",
       " '000000525600.jpg',\n",
       " '000000148730.jpg',\n",
       " '000000203864.jpg',\n",
       " '000000549220.jpg',\n",
       " '000000412894.jpg',\n",
       " '000000059044.jpg',\n",
       " '000000402473.jpg',\n",
       " '000000125129.jpg',\n",
       " '000000162732.jpg',\n",
       " '000000361571.jpg',\n",
       " '000000474452.jpg',\n",
       " '000000123633.jpg',\n",
       " '000000416256.jpg',\n",
       " '000000570782.jpg',\n",
       " '000000038678.jpg',\n",
       " '000000271402.jpg',\n",
       " '000000342397.jpg',\n",
       " '000000458109.jpg',\n",
       " '000000263796.jpg',\n",
       " '000000528862.jpg',\n",
       " '000000340930.jpg',\n",
       " '000000526728.jpg',\n",
       " '000000308430.jpg',\n",
       " '000000033221.jpg',\n",
       " '000000033638.jpg',\n",
       " '000000262631.jpg',\n",
       " '000000571804.jpg',\n",
       " '000000391722.jpg',\n",
       " '000000124798.jpg',\n",
       " '000000515577.jpg',\n",
       " '000000090003.jpg',\n",
       " '000000259382.jpg',\n",
       " '000000232348.jpg',\n",
       " '000000259625.jpg',\n",
       " '000000125850.jpg',\n",
       " '000000038829.jpg',\n",
       " '000000066841.jpg',\n",
       " '000000088269.jpg',\n",
       " '000000199771.jpg',\n",
       " '000000173799.jpg',\n",
       " '000000032735.jpg',\n",
       " '000000454067.jpg',\n",
       " '000000126216.jpg',\n",
       " '000000449406.jpg',\n",
       " '000000370711.jpg',\n",
       " '000000541773.jpg',\n",
       " '000000168974.jpg',\n",
       " '000000537827.jpg',\n",
       " '000000471789.jpg',\n",
       " '000000151857.jpg',\n",
       " '000000002153.jpg',\n",
       " '000000349678.jpg',\n",
       " '000000581781.jpg',\n",
       " '000000447465.jpg',\n",
       " '000000347370.jpg',\n",
       " '000000145020.jpg',\n",
       " '000000382125.jpg',\n",
       " '000000454404.jpg',\n",
       " '000000405195.jpg',\n",
       " '000000511398.jpg',\n",
       " '000000280891.jpg',\n",
       " '000000432553.jpg',\n",
       " '000000018833.jpg',\n",
       " '000000025057.jpg',\n",
       " '000000066706.jpg',\n",
       " '000000196442.jpg',\n",
       " '000000058655.jpg',\n",
       " '000000445722.jpg',\n",
       " '000000221017.jpg',\n",
       " '000000491497.jpg',\n",
       " '000000517069.jpg',\n",
       " '000000066135.jpg',\n",
       " '000000326128.jpg',\n",
       " '000000556158.jpg',\n",
       " '000000374545.jpg',\n",
       " '000000554266.jpg',\n",
       " '000000124636.jpg',\n",
       " '000000245576.jpg',\n",
       " '000000215723.jpg',\n",
       " '000000176901.jpg',\n",
       " '000000155051.jpg',\n",
       " '000000038048.jpg',\n",
       " '000000475484.jpg',\n",
       " '000000194940.jpg',\n",
       " '000000579321.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_val_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b9a19488f020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m##gt_labels = np.array(labels['category_id'].apply(np.array))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmap_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mcoco_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gluoncv/utils/metrics/voc_detection.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels, gt_difficults)\u001b[0m\n\u001b[1;32m    105\u001b[0m         for pred_bbox, pred_label, pred_score, gt_bbox, gt_label, gt_difficult in zip(\n\u001b[1;32m    106\u001b[0m                 *[as_numpy(x) for x in [pred_bboxes, pred_labels, pred_scores,\n\u001b[0;32m--> 107\u001b[0;31m                                         gt_bboxes, gt_labels, gt_difficults]]):\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;31m# strip padding -1 for pred and gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gluoncv/utils/metrics/voc_detection.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         for pred_bbox, pred_label, pred_score, gt_bbox, gt_label, gt_difficult in zip(\n\u001b[0;32m--> 106\u001b[0;31m                 *[as_numpy(x) for x in [pred_bboxes, pred_labels, pred_scores,\n\u001b[0m\u001b[1;32m    107\u001b[0m                                         gt_bboxes, gt_labels, gt_difficults]]):\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# strip padding -1 for pred and gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gluoncv/utils/metrics/voc_detection.py\u001b[0m in \u001b[0;36mas_numpy\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "#coco_metric.reset()\n",
    "\n",
    "#results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_2/'\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open#[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "#baseline_model = baseline.BaselineClassifier(model='faster_rcnn_resnet101_v1d_coco')\n",
    "baseline_model = baseline.BaselineClassifier(model='yolo3_darknet53_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "    #image_id = int(image[:-4])\n",
    "    #labels = val_electronics[val_electronics['image_id']==image_id]\n",
    "    #gt_bboxes = np.array([[coord for coord in entry] for entry in labels['bbox']]).reshape(1,len(labels),4)\n",
    "    ##gt_bboxes = np.array(labels['bbox'].apply(np.array))\n",
    "    #gt_labels = np.array([entry for entry in labels['category_id']]).reshape(1,len(labels))\n",
    "    ##gt_labels = np.array(labels['category_id'].apply(np.array))\n",
    "    \n",
    "    #map_object.update(bounding_boxes, class_ids.reshape(1,100), scores.reshape(1,100), gt_bboxes, gt_labels)\n",
    "    coco_metric.update(bounding_boxes, class_ids, scores)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.92s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['~~~~ Summary metrics ~~~~\\n',\n",
       "  'person',\n",
       "  'bicycle',\n",
       "  'car',\n",
       "  'motorcycle',\n",
       "  'airplane',\n",
       "  'bus',\n",
       "  'train',\n",
       "  'truck',\n",
       "  'boat',\n",
       "  'traffic light',\n",
       "  'fire hydrant',\n",
       "  'stop sign',\n",
       "  'parking meter',\n",
       "  'bench',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'horse',\n",
       "  'sheep',\n",
       "  'cow',\n",
       "  'elephant',\n",
       "  'bear',\n",
       "  'zebra',\n",
       "  'giraffe',\n",
       "  'backpack',\n",
       "  'umbrella',\n",
       "  'handbag',\n",
       "  'tie',\n",
       "  'suitcase',\n",
       "  'frisbee',\n",
       "  'skis',\n",
       "  'snowboard',\n",
       "  'sports ball',\n",
       "  'kite',\n",
       "  'baseball bat',\n",
       "  'baseball glove',\n",
       "  'skateboard',\n",
       "  'surfboard',\n",
       "  'tennis racket',\n",
       "  'bottle',\n",
       "  'wine glass',\n",
       "  'cup',\n",
       "  'fork',\n",
       "  'knife',\n",
       "  'spoon',\n",
       "  'bowl',\n",
       "  'banana',\n",
       "  'apple',\n",
       "  'sandwich',\n",
       "  'orange',\n",
       "  'broccoli',\n",
       "  'carrot',\n",
       "  'hot dog',\n",
       "  'pizza',\n",
       "  'donut',\n",
       "  'cake',\n",
       "  'chair',\n",
       "  'couch',\n",
       "  'potted plant',\n",
       "  'bed',\n",
       "  'dining table',\n",
       "  'toilet',\n",
       "  'tv',\n",
       "  'laptop',\n",
       "  'mouse',\n",
       "  'remote',\n",
       "  'keyboard',\n",
       "  'cell phone',\n",
       "  'microwave',\n",
       "  'oven',\n",
       "  'toaster',\n",
       "  'sink',\n",
       "  'refrigerator',\n",
       "  'book',\n",
       "  'clock',\n",
       "  'vase',\n",
       "  'scissors',\n",
       "  'teddy bear',\n",
       "  'hair drier',\n",
       "  'toothbrush',\n",
       "  '~~~~ MeanAP @ IoU=[0.50,0.95] ~~~~\\n'],\n",
       " ['Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0'])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map_object.get()\n",
    "coco_metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884.2778913974762"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>scores</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927936</td>\n",
       "      <td>70.859024</td>\n",
       "      <td>81.128845</td>\n",
       "      <td>162.252640</td>\n",
       "      <td>329.081268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>376.342072</td>\n",
       "      <td>282.334595</td>\n",
       "      <td>660.263550</td>\n",
       "      <td>518.431458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.356848</td>\n",
       "      <td>376.498962</td>\n",
       "      <td>289.023132</td>\n",
       "      <td>657.539246</td>\n",
       "      <td>509.743530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.326432</td>\n",
       "      <td>194.305130</td>\n",
       "      <td>31.842560</td>\n",
       "      <td>372.927612</td>\n",
       "      <td>205.119370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.145672</td>\n",
       "      <td>194.305130</td>\n",
       "      <td>31.842560</td>\n",
       "      <td>372.927612</td>\n",
       "      <td>205.119370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  class_id    scores           1           2           3  \\\n",
       "0  000000464476       0.0  0.927936   70.859024   81.128845  162.252640   \n",
       "1  000000464476      63.0  0.692063  376.342072  282.334595  660.263550   \n",
       "2  000000464476      62.0  0.356848  376.498962  289.023132  657.539246   \n",
       "3  000000464476       7.0  0.326432  194.305130   31.842560  372.927612   \n",
       "4  000000464476       6.0  0.145672  194.305130   31.842560  372.927612   \n",
       "\n",
       "            4  \n",
       "0  329.081268  \n",
       "1  518.431458  \n",
       "2  509.743530  \n",
       "3  205.119370  \n",
       "4  205.119370  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_test_annotations.to_csv('val_result_annotations_2.csv')\n",
    "all_test_annotations.to_csv('val_result_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = []#[0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies_by_class = []\n",
    "num_labels_detected = []\n",
    "num_labels = []\n",
    "unique_labels_by_image = []\n",
    "unique_preds_by_image = []\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    current_unique_preds = [0, 0, 0, 0, 0, 0]\n",
    "    current_unique_labels = [0, 0, 0, 0, 0, 0]\n",
    "    pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "    label_counts = [0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    unique_label_count = len(unique_labels)\n",
    "    unique_labels_detected = 0\n",
    "    for label in unique_labels:\n",
    "        #label_counts[label-72] += 1\n",
    "        current_unique_labels[label-72] += 1\n",
    "        if label in unique_preds:\n",
    "            unique_labels_detected += 1\n",
    "    for pred in unique_preds:\n",
    "        #pred_counts[pred-72] += 1\n",
    "        current_unique_preds[pred-72] += 1\n",
    "    \n",
    "    #new method: count instances of each id to take FP into account\n",
    "    \n",
    "    #new method: tally accuracy for each image separately\n",
    "    \n",
    "    #store counts of each label and pred for each image\n",
    "    total_pred_counts.append(pred_counts)\n",
    "    total_label_counts.append(label_counts)\n",
    "    \n",
    "    #store unique labels and preds\n",
    "    unique_labels_by_image.append(current_unique_labels)\n",
    "    unique_preds_by_image.append(current_unique_preds)\n",
    "    \n",
    "    #counts of unique labels and preds\n",
    "    num_labels.append(unique_label_count)\n",
    "    num_labels_detected.append(unique_labels_detected)\n",
    "    \n",
    "    #detection_accuracies.append(num_labels_detected/num_labels)\n",
    "    #detection_accuracies_by_class.append(list(np.divide(current_pred_counts, current_label_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.DataFrame(total_pred_counts)\n",
    "label_counts = pd.DataFrame(total_label_counts)\n",
    "pred_counts[6] = pred_counts.sum(axis=1)\n",
    "label_counts[6] = label_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6\n",
       "0  1  0  0  0  0  0  1\n",
       "1  1  0  0  0  0  0  1\n",
       "2  1  0  0  0  0  0  1\n",
       "3  1  0  0  0  0  0  1\n",
       "4  2  0  0  0  1  0  3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.431579\n",
       "1    0.366071\n",
       "2    0.314286\n",
       "3    0.709091\n",
       "4    0.543624\n",
       "5    0.630522\n",
       "6    0.476301\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = label_counts.subtract(pred_counts).abs()\n",
    "error_rate_by_class = errors.sum(axis=0).divide(label_counts.sum(axis=0))\n",
    "error_rate_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.52\n",
       "1    0.50\n",
       "2    0.00\n",
       "3    0.00\n",
       "4    0.25\n",
       "5    0.50\n",
       "6    0.40\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1. , 0. , 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 0. , 1. ,\n",
       "       1. , 0. , 0. , 0. , 0. , 1. , 1. , 1. , 0. , 1. , 1. ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.divide(num_labels_detected, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5712962962962963"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average percentage of unique electronics labels identified in a picture\n",
    "np.mean(np.divide(num_labels_detected, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = len(num_labels)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    141\n",
       "1    124\n",
       "2     65\n",
       "3     68\n",
       "4     66\n",
       "5     88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which of the unique labels were predicted?\n",
    "unique_labels_detected = (pd.DataFrame(unique_labels_by_image).astype(bool) & pd.DataFrame(unique_preds_by_image).astype(bool)).multiply(1).astype(int)\n",
    "unique_labels_detected.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204\n",
       "1    176\n",
       "2     87\n",
       "3    138\n",
       "4    103\n",
       "5    205\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_labeled = pd.DataFrame(unique_labels_by_image).sum(axis=0)\n",
    "num_images_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046002190580504"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall rate of detecting that a label is present\n",
    "unique_labels_detected.sum(axis=0).sum()/num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.691176\n",
       "1    0.704545\n",
       "2    0.747126\n",
       "3    0.492754\n",
       "4    0.640777\n",
       "5    0.429268\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each class, what fraction of images containing that class are predicted to contain that class?\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176078294692929"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average rate of detecting presence of a label, by class\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1     3\n",
       "2     2\n",
       "3     1\n",
       "4     3\n",
       "5     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_detected = pd.DataFrame(unique_preds_by_image).sum(axis=0)\n",
    "num_images_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.647059\n",
       "1    1.500000\n",
       "2    1.000000\n",
       "3    1.000000\n",
       "4    1.000000\n",
       "5    0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(num_images_detected, num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_3/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open#[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "baseline_model = baseline.BaselineClassifier(model='ssd_512_resnet50_v1_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564.4249608516693"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>scores</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.994084</td>\n",
       "      <td>377.621948</td>\n",
       "      <td>288.606720</td>\n",
       "      <td>652.204346</td>\n",
       "      <td>508.373383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991716</td>\n",
       "      <td>69.142776</td>\n",
       "      <td>77.343102</td>\n",
       "      <td>159.968185</td>\n",
       "      <td>331.558929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.315119</td>\n",
       "      <td>367.770813</td>\n",
       "      <td>51.634697</td>\n",
       "      <td>624.718262</td>\n",
       "      <td>280.566498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.197120</td>\n",
       "      <td>195.155273</td>\n",
       "      <td>32.164742</td>\n",
       "      <td>373.132996</td>\n",
       "      <td>200.863678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105416</td>\n",
       "      <td>527.026184</td>\n",
       "      <td>351.558197</td>\n",
       "      <td>537.178528</td>\n",
       "      <td>362.751556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098738</td>\n",
       "      <td>520.610962</td>\n",
       "      <td>352.366943</td>\n",
       "      <td>528.946655</td>\n",
       "      <td>362.981628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096872</td>\n",
       "      <td>530.714355</td>\n",
       "      <td>351.537720</td>\n",
       "      <td>541.468994</td>\n",
       "      <td>362.626953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090418</td>\n",
       "      <td>548.727539</td>\n",
       "      <td>353.481445</td>\n",
       "      <td>557.438843</td>\n",
       "      <td>363.910278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.084859</td>\n",
       "      <td>195.168060</td>\n",
       "      <td>31.367561</td>\n",
       "      <td>373.370697</td>\n",
       "      <td>204.342865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.081976</td>\n",
       "      <td>363.247223</td>\n",
       "      <td>109.605972</td>\n",
       "      <td>589.127808</td>\n",
       "      <td>501.856873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  class_id    scores           1           2           3  \\\n",
       "0  000000464476      62.0  0.994084  377.621948  288.606720  652.204346   \n",
       "1  000000464476       0.0  0.991716   69.142776   77.343102  159.968185   \n",
       "2  000000464476      62.0  0.315119  367.770813   51.634697  624.718262   \n",
       "3  000000464476       6.0  0.197120  195.155273   32.164742  373.132996   \n",
       "4  000000464476       0.0  0.105416  527.026184  351.558197  537.178528   \n",
       "5  000000464476       0.0  0.098738  520.610962  352.366943  528.946655   \n",
       "6  000000464476       0.0  0.096872  530.714355  351.537720  541.468994   \n",
       "7  000000464476       0.0  0.090418  548.727539  353.481445  557.438843   \n",
       "8  000000464476      62.0  0.084859  195.168060   31.367561  373.370697   \n",
       "9  000000464476      62.0  0.081976  363.247223  109.605972  589.127808   \n",
       "\n",
       "            4  \n",
       "0  508.373383  \n",
       "1  331.558929  \n",
       "2  280.566498  \n",
       "3  200.863678  \n",
       "4  362.751556  \n",
       "5  362.981628  \n",
       "6  362.626953  \n",
       "7  363.910278  \n",
       "8  204.342865  \n",
       "9  501.856873  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_annotations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_annotations.to_csv('val_result_annotations_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = [0, 0, 0, 0, 0, 0]\n",
    "pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "label_counts = [0, 0, 0, 0, 0, 0]\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        total_label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        total_pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    for label in unique_labels:\n",
    "        label_counts[label-72] += 1\n",
    "    for pred in unique_preds:\n",
    "        pred_counts[pred-72] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[212, 190, 76, 90, 98, 113]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[288, 230, 106, 282, 153, 259]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73611111, 0.82608696, 0.71698113, 0.31914894, 0.64052288,\n",
       "       0.43629344])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(total_pred_counts, total_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[172, 156, 62, 62, 78, 96]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[207, 182, 88, 144, 106, 211]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83091787, 0.85714286, 0.70454545, 0.43055556, 0.73584906,\n",
       "       0.4549763 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(pred_counts, label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6673773987206824"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_counts)/sum(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"Train YOLOv3 with random shapes.\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "import gluoncv as gcv\n",
    "from gluoncv import data as gdata\n",
    "from gluoncv import utils as gutils\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from gluoncv.data.transforms.presets.yolo import YOLO3DefaultTrainTransform\n",
    "from gluoncv.data.transforms.presets.yolo import YOLO3DefaultValTransform\n",
    "from gluoncv.data.dataloader import RandomTransformDataLoader\n",
    "from gluoncv.utils.metrics.voc_detection import VOC07MApMetric\n",
    "from gluoncv.utils.metrics.coco_detection import COCODetectionMetric\n",
    "from gluoncv.utils import LRScheduler, LRSequential\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train YOLO networks with random input shape.')\n",
    "    parser.add_argument('--network', type=str, default='darknet53',\n",
    "                        help=\"Base network name which serves as feature extraction base.\")\n",
    "    parser.add_argument('--data-shape', type=int, default=416,\n",
    "                        help=\"Input data shape for evaluation, use 320, 416, 608... \" +\n",
    "                             \"Training is with random shapes from (320 to 608).\")\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='Training mini-batch size')\n",
    "    parser.add_argument('--dataset', type=str, default='voc',\n",
    "                        help='Training dataset. Now support voc.')\n",
    "    parser.add_argument('--num-workers', '-j', dest='num_workers', type=int,\n",
    "                        default=4, help='Number of data workers, you can use larger '\n",
    "                        'number to accelerate data loading, if you CPU and GPUs are powerful.')\n",
    "    parser.add_argument('--gpus', type=str, default='0',\n",
    "                        help='Training with GPUs, you can specify 1,3 for example.')\n",
    "    parser.add_argument('--epochs', type=int, default=200,\n",
    "                        help='Training epochs.')\n",
    "    parser.add_argument('--resume', type=str, default='',\n",
    "                        help='Resume from previously saved parameters if not None. '\n",
    "                        'For example, you can resume from ./yolo3_xxx_0123.params')\n",
    "    parser.add_argument('--start-epoch', type=int, default=0,\n",
    "                        help='Starting epoch for resuming, default is 0 for new training.'\n",
    "                        'You can specify it to 100 for example to start from 100 epoch.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001,\n",
    "                        help='Learning rate, default is 0.001')\n",
    "    parser.add_argument('--lr-mode', type=str, default='step',\n",
    "                        help='learning rate scheduler mode. options are step, poly and cosine.')\n",
    "    parser.add_argument('--lr-decay', type=float, default=0.1,\n",
    "                        help='decay rate of learning rate. default is 0.1.')\n",
    "    parser.add_argument('--lr-decay-period', type=int, default=0,\n",
    "                        help='interval for periodic learning rate decays. default is 0 to disable.')\n",
    "    parser.add_argument('--lr-decay-epoch', type=str, default='160,180',\n",
    "                        help='epochs at which learning rate decays. default is 160,180.')\n",
    "    parser.add_argument('--warmup-lr', type=float, default=0.0,\n",
    "                        help='starting warmup learning rate. default is 0.0.')\n",
    "    parser.add_argument('--warmup-epochs', type=int, default=0,\n",
    "                        help='number of warmup epochs.')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='SGD momentum, default is 0.9')\n",
    "    parser.add_argument('--wd', type=float, default=0.0005,\n",
    "                        help='Weight decay, default is 5e-4')\n",
    "    parser.add_argument('--log-interval', type=int, default=100,\n",
    "                        help='Logging mini-batch interval. Default is 100.')\n",
    "    parser.add_argument('--save-prefix', type=str, default='',\n",
    "                        help='Saving parameter prefix')\n",
    "    parser.add_argument('--save-interval', type=int, default=10,\n",
    "                        help='Saving parameters epoch interval, best model will always be saved.')\n",
    "    parser.add_argument('--val-interval', type=int, default=1,\n",
    "                        help='Epoch interval for validation, increase the number will reduce the '\n",
    "                             'training time if validation is slow.')\n",
    "    parser.add_argument('--seed', type=int, default=233,\n",
    "                        help='Random seed to be fixed.')\n",
    "    parser.add_argument('--num-samples', type=int, default=-1,\n",
    "                        help='Training images. Use -1 to automatically get the number.')\n",
    "    parser.add_argument('--syncbn', action='store_true',\n",
    "                        help='Use synchronize BN across devices.')\n",
    "    parser.add_argument('--no-random-shape', action='store_true',\n",
    "                        help='Use fixed size(data-shape) throughout the training, which will be faster '\n",
    "                        'and require less memory. However, final model will be slightly worse.')\n",
    "    parser.add_argument('--no-wd', action='store_true',\n",
    "                        help='whether to remove weight decay on bias, and beta/gamma for batchnorm layers.')\n",
    "    parser.add_argument('--mixup', action='store_true',\n",
    "                        help='whether to enable mixup.')\n",
    "    parser.add_argument('--no-mixup-epochs', type=int, default=20,\n",
    "                        help='Disable mixup training if enabled in the last N epochs.')\n",
    "    parser.add_argument('--label-smooth', action='store_true', help='Use label smoothing.')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_dataset(dataset, args):\n",
    "    if dataset.lower() == 'voc':\n",
    "        train_dataset = gdata.VOCDetection(\n",
    "            splits=[(2007, 'trainval'), (2012, 'trainval')])\n",
    "        val_dataset = gdata.VOCDetection(\n",
    "            splits=[(2007, 'test')])\n",
    "        val_metric = VOC07MApMetric(iou_thresh=0.5, class_names=val_dataset.classes)\n",
    "    elif dataset.lower() == 'coco':\n",
    "        train_dataset = gdata.COCODetection(splits='instances_train2017', use_crowd=False)\n",
    "        val_dataset = gdata.COCODetection(splits='instances_val2017', skip_empty=False)\n",
    "        val_metric = COCODetectionMetric(\n",
    "            val_dataset, args.save_prefix + '_eval', cleanup=True,\n",
    "            data_shape=(args.data_shape, args.data_shape))\n",
    "    else:\n",
    "        raise NotImplementedError('Dataset: {} not implemented.'.format(dataset))\n",
    "    if args.num_samples < 0:\n",
    "        args.num_samples = len(train_dataset)\n",
    "    if args.mixup:\n",
    "        from gluoncv.data import MixupDetection\n",
    "        train_dataset = MixupDetection(train_dataset)\n",
    "    return train_dataset, val_dataset, val_metric\n",
    "\n",
    "def get_dataloader(net, train_dataset, val_dataset, data_shape, batch_size, num_workers, args):\n",
    "    \"\"\"Get dataloader.\"\"\"\n",
    "    width, height = data_shape, data_shape\n",
    "    batchify_fn = Tuple(*([Stack() for _ in range(6)] + [Pad(axis=0, pad_val=-1) for _ in range(1)]))  # stack image, all targets generated\n",
    "    if args.no_random_shape:\n",
    "        train_loader = gluon.data.DataLoader(\n",
    "            train_dataset.transform(YOLO3DefaultTrainTransform(width, height, net, mixup=args.mixup)),\n",
    "            batch_size, True, batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "    else:\n",
    "        transform_fns = [YOLO3DefaultTrainTransform(x * 32, x * 32, net, mixup=args.mixup) for x in range(10, 20)]\n",
    "        train_loader = RandomTransformDataLoader(\n",
    "            transform_fns, train_dataset, batch_size=batch_size, interval=10, last_batch='rollover',\n",
    "            shuffle=True, batchify_fn=batchify_fn, num_workers=num_workers)\n",
    "    val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "    val_loader = gluon.data.DataLoader(\n",
    "        val_dataset.transform(YOLO3DefaultValTransform(width, height)),\n",
    "        batch_size, False, batchify_fn=val_batchify_fn, last_batch='keep', num_workers=num_workers)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def save_params(net, best_map, current_map, epoch, save_interval, prefix):\n",
    "    current_map = float(current_map)\n",
    "    if current_map > best_map[0]:\n",
    "        best_map[0] = current_map\n",
    "        net.save_parameters('{:s}_best.params'.format(prefix, epoch, current_map))\n",
    "        with open(prefix+'_best_map.log', 'a') as f:\n",
    "            f.write('{:04d}:\\t{:.4f}\\n'.format(epoch, current_map))\n",
    "    if save_interval and epoch % save_interval == 0:\n",
    "        net.save_parameters('{:s}_{:04d}_{:.4f}.params'.format(prefix, epoch, current_map))\n",
    "\n",
    "def validate(net, val_data, ctx, eval_metric):\n",
    "    \"\"\"Test on validation dataset.\"\"\"\n",
    "    eval_metric.reset()\n",
    "    # set nms threshold and topk constraint\n",
    "    net.set_nms(nms_thresh=0.45, nms_topk=400)\n",
    "    mx.nd.waitall()\n",
    "    net.hybridize()\n",
    "    for batch in val_data:\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        det_bboxes = []\n",
    "        det_ids = []\n",
    "        det_scores = []\n",
    "        gt_bboxes = []\n",
    "        gt_ids = []\n",
    "        gt_difficults = []\n",
    "        for x, y in zip(data, label):\n",
    "            # get prediction results\n",
    "            ids, scores, bboxes = net(x)\n",
    "            det_ids.append(ids)\n",
    "            det_scores.append(scores)\n",
    "            # clip to image size\n",
    "            det_bboxes.append(bboxes.clip(0, batch[0].shape[2]))\n",
    "            # split ground truths\n",
    "            gt_ids.append(y.slice_axis(axis=-1, begin=4, end=5))\n",
    "            gt_bboxes.append(y.slice_axis(axis=-1, begin=0, end=4))\n",
    "            gt_difficults.append(y.slice_axis(axis=-1, begin=5, end=6) if y.shape[-1] > 5 else None)\n",
    "\n",
    "        # update metric\n",
    "        eval_metric.update(det_bboxes, det_ids, det_scores, gt_bboxes, gt_ids, gt_difficults)\n",
    "    return eval_metric.get()\n",
    "\n",
    "def train(net, train_data, val_data, eval_metric, ctx, args):\n",
    "    \"\"\"Training pipeline\"\"\"\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    if args.no_wd:\n",
    "        for k, v in net.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "            v.wd_mult = 0.0\n",
    "\n",
    "    if args.label_smooth:\n",
    "        net._target_generator._label_smooth = True\n",
    "\n",
    "    if args.lr_decay_period > 0:\n",
    "        lr_decay_epoch = list(range(args.lr_decay_period, args.epochs, args.lr_decay_period))\n",
    "    else:\n",
    "        lr_decay_epoch = [int(i) for i in args.lr_decay_epoch.split(',')]\n",
    "    lr_decay_epoch = [e - args.warmup_epochs for e in lr_decay_epoch]\n",
    "    num_batches = args.num_samples // args.batch_size\n",
    "    lr_scheduler = LRSequential([\n",
    "        LRScheduler('linear', base_lr=0, target_lr=args.lr,\n",
    "                    nepochs=args.warmup_epochs, iters_per_epoch=num_batches),\n",
    "        LRScheduler(args.lr_mode, base_lr=args.lr,\n",
    "                    nepochs=args.epochs - args.warmup_epochs,\n",
    "                    iters_per_epoch=num_batches,\n",
    "                    step_epoch=lr_decay_epoch,\n",
    "                    step_factor=args.lr_decay, power=2),\n",
    "    ])\n",
    "\n",
    "    trainer = gluon.Trainer(\n",
    "        net.collect_params(), 'sgd',\n",
    "        {'wd': args.wd, 'momentum': args.momentum, 'lr_scheduler': lr_scheduler},\n",
    "        kvstore='local')\n",
    "\n",
    "    # targets\n",
    "    sigmoid_ce = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "    l1_loss = gluon.loss.L1Loss()\n",
    "\n",
    "    # metrics\n",
    "    obj_metrics = mx.metric.Loss('ObjLoss')\n",
    "    center_metrics = mx.metric.Loss('BoxCenterLoss')\n",
    "    scale_metrics = mx.metric.Loss('BoxScaleLoss')\n",
    "    cls_metrics = mx.metric.Loss('ClassLoss')\n",
    "\n",
    "    # set up logger\n",
    "    logging.basicConfig()\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    log_file_path = args.save_prefix + '_train.log'\n",
    "    log_dir = os.path.dirname(log_file_path)\n",
    "    if log_dir and not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    fh = logging.FileHandler(log_file_path)\n",
    "    logger.addHandler(fh)\n",
    "    logger.info(args)\n",
    "    logger.info('Start training from [Epoch {}]'.format(args.start_epoch))\n",
    "    best_map = [0]\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.mixup:\n",
    "            # TODO(zhreshold): more elegant way to control mixup during runtime\n",
    "            try:\n",
    "                train_data._dataset.set_mixup(np.random.beta, 1.5, 1.5)\n",
    "            except AttributeError:\n",
    "                train_data._dataset._data.set_mixup(np.random.beta, 1.5, 1.5)\n",
    "            if epoch >= args.epochs - args.no_mixup_epochs:\n",
    "                try:\n",
    "                    train_data._dataset.set_mixup(None)\n",
    "                except AttributeError:\n",
    "                    train_data._dataset._data.set_mixup(None)\n",
    "\n",
    "        tic = time.time()\n",
    "        btic = time.time()\n",
    "        mx.nd.waitall()\n",
    "        net.hybridize()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            batch_size = batch[0].shape[0]\n",
    "            data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "            # objectness, center_targets, scale_targets, weights, class_targets\n",
    "            fixed_targets = [gluon.utils.split_and_load(batch[it], ctx_list=ctx, batch_axis=0) for it in range(1, 6)]\n",
    "            gt_boxes = gluon.utils.split_and_load(batch[6], ctx_list=ctx, batch_axis=0)\n",
    "            sum_losses = []\n",
    "            obj_losses = []\n",
    "            center_losses = []\n",
    "            scale_losses = []\n",
    "            cls_losses = []\n",
    "            with autograd.record():\n",
    "                for ix, x in enumerate(data):\n",
    "                    obj_loss, center_loss, scale_loss, cls_loss = net(x, gt_boxes[ix], *[ft[ix] for ft in fixed_targets])\n",
    "                    sum_losses.append(obj_loss + center_loss + scale_loss + cls_loss)\n",
    "                    obj_losses.append(obj_loss)\n",
    "                    center_losses.append(center_loss)\n",
    "                    scale_losses.append(scale_loss)\n",
    "                    cls_losses.append(cls_loss)\n",
    "                autograd.backward(sum_losses)\n",
    "            trainer.step(batch_size)\n",
    "            obj_metrics.update(0, obj_losses)\n",
    "            center_metrics.update(0, center_losses)\n",
    "            scale_metrics.update(0, scale_losses)\n",
    "            cls_metrics.update(0, cls_losses)\n",
    "            if args.log_interval and not (i + 1) % args.log_interval:\n",
    "                name1, loss1 = obj_metrics.get()\n",
    "                name2, loss2 = center_metrics.get()\n",
    "                name3, loss3 = scale_metrics.get()\n",
    "                name4, loss4 = cls_metrics.get()\n",
    "                logger.info('[Epoch {}][Batch {}], LR: {:.2E}, Speed: {:.3f} samples/sec, {}={:.3f}, {}={:.3f}, {}={:.3f}, {}={:.3f}'.format(\n",
    "                    epoch, i, trainer.learning_rate, batch_size/(time.time()-btic), name1, loss1, name2, loss2, name3, loss3, name4, loss4))\n",
    "            btic = time.time()\n",
    "\n",
    "        name1, loss1 = obj_metrics.get()\n",
    "        name2, loss2 = center_metrics.get()\n",
    "        name3, loss3 = scale_metrics.get()\n",
    "        name4, loss4 = cls_metrics.get()\n",
    "        logger.info('[Epoch {}] Training cost: {:.3f}, {}={:.3f}, {}={:.3f}, {}={:.3f}, {}={:.3f}'.format(\n",
    "            epoch, (time.time()-tic), name1, loss1, name2, loss2, name3, loss3, name4, loss4))\n",
    "        if not (epoch + 1) % args.val_interval:\n",
    "            # consider reduce the frequency of validation to save time\n",
    "            map_name, mean_ap = validate(net, val_data, ctx, eval_metric)\n",
    "            val_msg = '\\n'.join(['{}={}'.format(k, v) for k, v in zip(map_name, mean_ap)])\n",
    "            logger.info('[Epoch {}] Validation: \\n{}'.format(epoch, val_msg))\n",
    "            current_map = float(mean_ap[-1])\n",
    "        else:\n",
    "            current_map = 0.\n",
    "        save_params(net, best_map, current_map, epoch, args.save_interval, args.save_prefix)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    args = parse_args()\n",
    "#    # fix seed for mxnet, numpy and python builtin random generator.\n",
    "#    gutils.random.seed(args.seed)\n",
    "\n",
    "#    # training contexts\n",
    "#    ctx = [mx.gpu(int(i)) for i in args.gpus.split(',') if i.strip()]\n",
    "#    ctx = ctx if ctx else [mx.cpu()]\n",
    "\n",
    "#    # network\n",
    "#    net_name = '_'.join(('yolo3', args.network, args.dataset))\n",
    "#    args.save_prefix += net_name\n",
    "#    # use sync bn if specified\n",
    "#    if args.syncbn and len(ctx) > 1:\n",
    "#        net = get_model(net_name, pretrained_base=True, norm_layer=gluon.contrib.nn.SyncBatchNorm,\n",
    "#                        norm_kwargs={'num_devices': len(ctx)})\n",
    "#        async_net = get_model(net_name, pretrained_base=False)  # used by cpu worker\n",
    "#    else:\n",
    "#        net = get_model(net_name, pretrained_base=True)\n",
    "#        async_net = net\n",
    "#    if args.resume.strip():\n",
    "#        net.load_parameters(args.resume.strip())\n",
    "#        async_net.load_parameters(args.resume.strip())\n",
    "#    else:\n",
    "#        with warnings.catch_warnings(record=True) as w:\n",
    "#            warnings.simplefilter(\"always\")\n",
    "#            net.initialize()\n",
    "#            async_net.initialize()\n",
    "\n",
    "#    # training data\n",
    "#    train_dataset, val_dataset, eval_metric = get_dataset(args.dataset, args)\n",
    "#    train_data, val_data = get_dataloader(\n",
    "#        async_net, train_dataset, val_dataset, args.data_shape, args.batch_size, args.num_workers, args)\n",
    "\n",
    "#    # training\n",
    "#    train(net, train_data, val_data, eval_metric, ctx, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "# fix seed for mxnet, numpy and python builtin random generator.\n",
    "gutils.random.seed(1)\n",
    "\n",
    "# training contexts\n",
    "#ctx = [mx.gpu(int(i)) for i in args.gpus.split(',') if i.strip()]\n",
    "ctx = ctx if ctx else [mx.cpu()]\n",
    "ctx = [mx.cpu()]\n",
    "\n",
    "# network\n",
    "net_name = '_'.join(('yolo3', args.network, args.dataset))\n",
    "args.save_prefix += net_name\n",
    "# use sync bn if specified\n",
    "if args.syncbn and len(ctx) > 1:\n",
    "    net = get_model(net_name, pretrained_base=True, norm_layer=gluon.contrib.nn.SyncBatchNorm,\n",
    "                    norm_kwargs={'num_devices': len(ctx)})\n",
    "    async_net = get_model(net_name, pretrained_base=False)  # used by cpu worker\n",
    "else:\n",
    "    net = get_model(net_name, pretrained_base=True)\n",
    "    async_net = net\n",
    "if args.resume.strip():\n",
    "    net.load_parameters(args.resume.strip())\n",
    "    async_net.load_parameters(args.resume.strip())\n",
    "else:\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        net.initialize()\n",
    "        async_net.initialize()\n",
    "\n",
    "# training data\n",
    "train_dataset, val_dataset, eval_metric = get_dataset(args.dataset, args)\n",
    "train_data, val_data = get_dataloader(\n",
    "    async_net, train_dataset, val_dataset, args.data_shape, args.batch_size, args.num_workers, args)\n",
    "\n",
    "# training\n",
    "train(net, train_data, val_data, eval_metric, ctx, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "import gluoncv as gcv\n",
    "from gluoncv import data as gdata\n",
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from gluoncv.data.transforms.presets.yolo import YOLO3DefaultValTransform\n",
    "from gluoncv.utils.metrics.voc_detection import VOC07MApMetric\n",
    "from gluoncv.utils.metrics.coco_detection import COCODetectionMetric\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Eval YOLO networks.')\n",
    "    parser.add_argument('--network', type=str, default='darknet53',\n",
    "                        help=\"Base network name\")\n",
    "    parser.add_argument('--algorithm', type=str, default='yolo3',\n",
    "                        help='YOLO version, default is yolo3')\n",
    "    parser.add_argument('--data-shape', type=int, default=416,\n",
    "                        help=\"Input data shape\")\n",
    "    parser.add_argument('--batch-size', type=int, default=64,\n",
    "                        help='Training mini-batch size')\n",
    "    parser.add_argument('--dataset', type=str, default='voc',\n",
    "                        help='Training dataset.')\n",
    "    parser.add_argument('--num-workers', '-j', dest='num_workers', type=int,\n",
    "                        default=4, help='Number of data workers')\n",
    "    parser.add_argument('--gpus', type=str, default='0',\n",
    "                        help='Training with GPUs, you can specify 1,3 for example.')\n",
    "    parser.add_argument('--pretrained', type=str, default='True',\n",
    "                        help='Load weights from previously saved parameters.')\n",
    "    parser.add_argument('--save-prefix', type=str, default='',\n",
    "                        help='Saving parameter prefix')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_dataset(dataset, data_shape):\n",
    "    if dataset.lower() == 'voc':\n",
    "        val_dataset = gdata.VOCDetection(splits=[(2007, 'test')])\n",
    "        val_metric = VOC07MApMetric(iou_thresh=0.5, class_names=val_dataset.classes)\n",
    "    elif dataset.lower() == 'coco':\n",
    "        val_dataset = gdata.COCODetection(splits='instances_val2017', skip_empty=False)\n",
    "        val_metric = COCODetectionMetric(\n",
    "            val_dataset, args.save_prefix + '_eval', cleanup=True,\n",
    "            data_shape=(data_shape, data_shape))\n",
    "    else:\n",
    "        raise NotImplementedError('Dataset: {} not implemented.'.format(dataset))\n",
    "    return val_dataset, val_metric\n",
    "\n",
    "def get_dataloader(val_dataset, data_shape, batch_size, num_workers):\n",
    "    \"\"\"Get dataloader.\"\"\"\n",
    "    width, height = data_shape, data_shape\n",
    "    batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "    val_loader = gluon.data.DataLoader(\n",
    "        val_dataset.transform(YOLO3DefaultValTransform(width, height)),\n",
    "        batch_size, False, last_batch='keep', num_workers=num_workers, batchify_fn=batchify_fn,)\n",
    "    return val_loader\n",
    "\n",
    "def validate(net, val_data, ctx, classes, size, metric):\n",
    "    \"\"\"Test on validation dataset.\"\"\"\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    metric.reset()\n",
    "    net.set_nms(nms_thresh=0.45, nms_topk=400)\n",
    "    net.hybridize()\n",
    "    with tqdm(total=size) as pbar:\n",
    "        for ib, batch in enumerate(val_data):\n",
    "            data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "            label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "            det_bboxes = []\n",
    "            det_ids = []\n",
    "            det_scores = []\n",
    "            gt_bboxes = []\n",
    "            gt_ids = []\n",
    "            gt_difficults = []\n",
    "            for x, y in zip(data, label):\n",
    "                ids, scores, bboxes = net(x)\n",
    "                det_ids.append(ids)\n",
    "                det_scores.append(scores)\n",
    "                # clip to image size\n",
    "                det_bboxes.append(bboxes.clip(0, batch[0].shape[2]))\n",
    "                # split ground truths\n",
    "                gt_ids.append(y.slice_axis(axis=-1, begin=4, end=5))\n",
    "                gt_bboxes.append(y.slice_axis(axis=-1, begin=0, end=4))\n",
    "                gt_difficults.append(y.slice_axis(axis=-1, begin=5, end=6) if y.shape[-1] > 5 else None)\n",
    "\n",
    "            metric.update(det_bboxes, det_ids, det_scores, gt_bboxes, gt_ids, gt_difficults)\n",
    "            pbar.update(batch[0].shape[0])\n",
    "    return metric.get()\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    args = parse_args()\n",
    "#\n",
    "#    # training contexts\n",
    "#    ctx = [mx.gpu(int(i)) for i in args.gpus.split(',') if i.strip()]\n",
    "#    ctx = ctx if ctx else [mx.cpu()]\n",
    "\n",
    "#    # network\n",
    "#    net_name = '_'.join((args.algorithm, args.network, args.dataset))\n",
    "#    args.save_prefix += net_name\n",
    "#    if args.pretrained.lower() in ['true', '1', 'yes', 't']:\n",
    "#        net = gcv.model_zoo.get_model(net_name, pretrained=True)\n",
    "#    else:\n",
    "#        net = gcv.model_zoo.get_model(net_name, pretrained=False)\n",
    "#        net.load_parameters(args.pretrained.strip())\n",
    "\n",
    "#    # training data\n",
    "#    val_dataset, val_metric = get_dataset(args.dataset, args.data_shape)\n",
    "#    val_data = get_dataloader(\n",
    "#        val_dataset, args.data_shape, args.batch_size, args.num_workers)\n",
    "#    classes = val_dataset.classes  # class names\n",
    "\n",
    "#    # training\n",
    "#    names, values = validate(net, val_data, ctx, classes, len(val_dataset), val_metric)\n",
    "#    for k, v in zip(names, values):\n",
    "#        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5000/5000 [27:50<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.97s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=22.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=2.87s).\n",
      "~~~~ Summary metrics ~~~~\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.497\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
      "person 41.9\n",
      "bicycle 22.1\n",
      "car 27.1\n",
      "motorcycle 33.1\n",
      "airplane 56.6\n",
      "bus 57.3\n",
      "train 58.6\n",
      "truck 29.0\n",
      "boat 16.8\n",
      "traffic light 13.0\n",
      "fire hydrant 54.1\n",
      "stop sign 54.9\n",
      "parking meter 42.0\n",
      "bench 15.8\n",
      "bird 23.0\n",
      "cat 58.4\n",
      "dog 55.2\n",
      "horse 48.4\n",
      "sheep 38.8\n",
      "cow 41.0\n",
      "elephant 54.2\n",
      "bear 60.4\n",
      "zebra 55.7\n",
      "giraffe 55.1\n",
      "backpack 8.5\n",
      "umbrella 31.6\n",
      "handbag 5.8\n",
      "tie 22.2\n",
      "suitcase 21.9\n",
      "frisbee 42.4\n",
      "skis 15.0\n",
      "snowboard 20.1\n",
      "sports ball 24.1\n",
      "kite 24.3\n",
      "baseball bat 16.3\n",
      "baseball glove 21.7\n",
      "skateboard 40.6\n",
      "surfboard 26.4\n",
      "tennis racket 34.2\n",
      "bottle 19.8\n",
      "wine glass 21.7\n",
      "cup 27.4\n",
      "fork 21.2\n",
      "knife 8.2\n",
      "spoon 7.6\n",
      "bowl 32.6\n",
      "banana 17.3\n",
      "apple 10.9\n",
      "sandwich 31.1\n",
      "orange 23.5\n",
      "broccoli 18.2\n",
      "carrot 13.0\n",
      "hot dog 22.7\n",
      "pizza 43.5\n",
      "donut 18.6\n",
      "cake 26.9\n",
      "chair 19.3\n",
      "couch 37.9\n",
      "potted plant 16.6\n",
      "bed 38.9\n",
      "dining table 24.8\n",
      "toilet 51.1\n",
      "tv 50.4\n",
      "laptop 51.8\n",
      "mouse 43.1\n",
      "remote 14.3\n",
      "keyboard 43.0\n",
      "cell phone 23.0\n",
      "microwave 47.5\n",
      "oven 23.6\n",
      "toaster 22.7\n",
      "sink 26.2\n",
      "refrigerator 44.7\n",
      "book 5.5\n",
      "clock 36.8\n",
      "vase 21.8\n",
      "scissors 20.6\n",
      "teddy bear 35.8\n",
      "hair drier 0.0\n",
      "toothbrush 11.7\n",
      "~~~~ MeanAP @ IoU=[0.50,0.95] ~~~~\n",
      " 30.5\n"
     ]
    }
   ],
   "source": [
    "#args = parse_args()\n",
    "\n",
    "## training contexts\n",
    "#ctx = [mx.gpu(int(i)) for i in args.gpus.split(',') if i.strip()]\n",
    "#ctx = ctx if ctx else [mx.cpu()]\n",
    "ctx = [mx.cpu()]\n",
    "\n",
    "# network\n",
    "#net_name = '_'.join((args.algorithm, args.network, args.dataset))\n",
    "#args.save_prefix += net_name\n",
    "#if args.pretrained.lower() in ['true', '1', 'yes', 't']:\n",
    "#    net = gcv.model_zoo.get_model(net_name, pretrained=True)\n",
    "#else:\n",
    "#    net = gcv.model_zoo.get_model(net_name, pretrained=False)\n",
    "#    net.load_parameters(args.pretrained.strip())\n",
    "    \n",
    "\n",
    "\n",
    "# training data\n",
    "#val_dataset, val_metric = get_dataset(args.dataset, args.data_shape)\n",
    "#val_data = get_dataloader(val_dataset, args.data_shape, args.batch_size, args.num_workers)\n",
    "#classes = val_dataset.classes  # class names\n",
    "\n",
    "net_name = 'ssd_512_resnet50_v1_coco'\n",
    "net = gcv.model_zoo.get_model(net_name, pretrained=True)\n",
    "data_shape = 512\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "val_dataset = gdata.COCODetection(root='/mnt/muthderd/MIDS/W210/data/', splits='/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_val2017', skip_empty=False)\n",
    "val_data = get_dataloader(val_dataset, data_shape, batch_size, num_workers)\n",
    "#val_dataset = gdata.COCODetection(splits='instances_val2017', skip_empty=False)\n",
    "val_metric = COCODetectionMetric(val_dataset, 'test_eval', cleanup=True, data_shape=(data_shape, data_shape))\n",
    "classes = val_dataset.classes  # class names\n",
    "\n",
    "# training\n",
    "names, values = validate(net, val_data, ctx, classes, len(val_dataset), val_metric)\n",
    "for k, v in zip(names, values):\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702.4682216644287"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
