{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:01:33.484381Z",
     "start_time": "2019-02-10T15:01:33.481061Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import baseline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#TEMPORARILY SUPPRESS WARNINGS\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the actual labels in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:02:49.241219Z",
     "start_time": "2019-02-10T15:02:47.586565Z"
    }
   },
   "outputs": [],
   "source": [
    "captions_train_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/captions_train2017.json\"\n",
    "captions_val_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/captions_val2017.json\"\n",
    "#captions_train  = json.loads(open(captions_train_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T15:30:21.837928Z",
     "start_time": "2019-02-10T15:29:52.465683Z"
    }
   },
   "outputs": [],
   "source": [
    "inst_train_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_train2017.json\"\n",
    "inst_val_path = \"/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_val2017.json\"\n",
    "#inst_train  = json.loads(open(inst_train_path).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electronics_info(captions_path, inst_path):\n",
    "    captions  = json.loads(open(captions_path).read())\n",
    "    inst  = json.loads(open(inst_path).read())\n",
    "    image_df = pd.DataFrame(inst['images'])\n",
    "    annotation_df = pd.DataFrame(inst['annotations'])\n",
    "    #the 'id' in image_df needs to be changed to 'image_id' in order to join with annotations_df\n",
    "    renamed_image_df = image_df.copy(deep=True)\n",
    "    renamed_image_df.rename(columns={'id':'image_id'}, inplace=True)\n",
    "    images_and_annotations_df = annotation_df.merge(renamed_image_df,on='image_id', how='left')\n",
    "    electronics_only_merged_df = images_and_annotations_df.loc[(images_and_annotations_df['category_id'] >= 72) & (images_and_annotations_df['category_id'] <= 77)]\n",
    "    \n",
    "    #select all images that contain electronics\n",
    "    #all_images_with_electronics = list(pd.Series(electronics_only_merged_df['image_id']).unique())\n",
    "    \n",
    "    return(electronics_only_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_electronics = get_electronics_info(captions_train_path, inst_train_path)\n",
    "val_electronics = get_electronics_info(captions_val_path, inst_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#val_electronics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>coco_url</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flickr_url</th>\n",
       "      <th>height</th>\n",
       "      <th>license</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24452</th>\n",
       "      <td>13244.65770</td>\n",
       "      <td>[7.03, 167.76, 149.32, 94.87]</td>\n",
       "      <td>72</td>\n",
       "      <td>34646</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>[[9.66, 167.76, 156.35, 173.04, 153.71, 256.48...</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000000...</td>\n",
       "      <td>2013-11-21 01:34:01</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>http://farm9.staticflickr.com/8035/8024364858_...</td>\n",
       "      <td>426</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24458</th>\n",
       "      <td>5833.11795</td>\n",
       "      <td>[557.21, 209.19, 81.35, 78.73]</td>\n",
       "      <td>72</td>\n",
       "      <td>35802</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>[[563.33, 209.19, 637.69, 209.19, 638.56, 287....</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000000...</td>\n",
       "      <td>2013-11-21 01:34:01</td>\n",
       "      <td>000000000139.jpg</td>\n",
       "      <td>http://farm9.staticflickr.com/8035/8024364858_...</td>\n",
       "      <td>426</td>\n",
       "      <td>2</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              area                            bbox  category_id     id  \\\n",
       "24452  13244.65770   [7.03, 167.76, 149.32, 94.87]           72  34646   \n",
       "24458   5833.11795  [557.21, 209.19, 81.35, 78.73]           72  35802   \n",
       "\n",
       "       image_id  iscrowd                                       segmentation  \\\n",
       "24452       139        0  [[9.66, 167.76, 156.35, 173.04, 153.71, 256.48...   \n",
       "24458       139        0  [[563.33, 209.19, 637.69, 209.19, 638.56, 287....   \n",
       "\n",
       "                                                coco_url        date_captured  \\\n",
       "24452  http://images.cocodataset.org/val2017/00000000...  2013-11-21 01:34:01   \n",
       "24458  http://images.cocodataset.org/val2017/00000000...  2013-11-21 01:34:01   \n",
       "\n",
       "              file_name                                         flickr_url  \\\n",
       "24452  000000000139.jpg  http://farm9.staticflickr.com/8035/8024364858_...   \n",
       "24458  000000000139.jpg  http://farm9.staticflickr.com/8035/8024364858_...   \n",
       "\n",
       "       height  license  width  \n",
       "24452     426        2    640  \n",
       "24458     426        2    640  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_electronics[val_electronics['image_id']==139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_electronics[val_electronics['image_id']==464476]['bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[279.11, 209.81, 206.02, 160.44],\n",
       "        [281.13,  40.81, 165.48, 166.35]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[coord for coord in entry] for entry in val_electronics[val_electronics['image_id']==464476]['bbox']]).reshape(1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (1,2,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-583d4d357f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_electronics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_electronics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m464476\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,2,4)"
     ]
    }
   ],
   "source": [
    "np.array(val_electronics[val_electronics['image_id']==464476]['bbox'].apply(np.array)).reshape(1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 72]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_electronics[val_electronics['image_id']==464476]['category_id']\n",
    "np.array([entry for entry in val_electronics[val_electronics['image_id']==464476]['category_id']]).reshape(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract electronics IDs in each image\n",
    "eIDs_in_images = val_electronics.groupby('image_id')['category_id'].apply(list).to_dict()\n",
    "#select all images that contain electronics\n",
    "train_images_with_electronics = list(pd.Series(train_electronics['image_id']).unique())\n",
    "val_images_with_electronics = list(pd.Series(val_electronics['image_id']).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_images_with_electronics[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_images_with_electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the validation images with electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder_name = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "all_val_filenames = os.listdir(val_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_file_id_length = len(all_val_filenames[0]) - 4#subtract 4 for the '.jpg' suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_open = []\n",
    "for image_id in val_images_with_electronics:\n",
    "    file_id = str(image_id)\n",
    "    zeros_to_add = max_file_id_length-len(file_id)\n",
    "    filename = ('0'*zeros_to_add) + file_id + '.jpg'\n",
    "    files_to_open.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files_to_open[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv import data as gdata\n",
    "from gluoncv import utils as gutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "map_data = gdata.COCODetection(root='/mnt/muthderd/MIDS/W210/data/', splits='/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_val2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASSES',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_load_bbox',\n",
       " '_coco',\n",
       " '_items',\n",
       " '_labels',\n",
       " '_load_jsons',\n",
       " '_min_object_area',\n",
       " '_root',\n",
       " '_skip_empty',\n",
       " '_splits',\n",
       " '_transform',\n",
       " '_use_crowd',\n",
       " 'classes',\n",
       " 'coco',\n",
       " 'contiguous_id_to_json',\n",
       " 'index_map',\n",
       " 'json_id_to_contiguous',\n",
       " 'num_class',\n",
       " 'transform',\n",
       " 'transform_first']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gluoncv.data.mscoco.detection.COCODetection"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_metric = gutils.metrics.COCODetectionMetric(map_data, save_prefix='/mnt/muthderd/MIDS/W210/data/annotations_trainval2017/annotations/instances_val2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coco_metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_object = gutils.metrics.VOCMApMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[279.11, 209.81, 206.02, 160.44],\n",
       "        [281.13,  40.81, 165.48, 166.35]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_bboxes#.reshape(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 70.859024  81.128845 162.25264  329.08127 ]\n",
       " [376.34207  282.3346   660.26355  518.43146 ]\n",
       " [376.49896  289.02313  657.53925  509.74353 ]\n",
       " [194.30513   31.84256  372.9276   205.11937 ]\n",
       " [194.30513   31.84256  372.9276   205.11937 ]\n",
       " [206.42798   34.58731  375.59808  202.87526 ]\n",
       " [ 27.974426  10.990707 389.3849   263.2132  ]\n",
       " [374.799     49.53401  609.736    288.7542  ]\n",
       " [ 72.88392  173.17085   97.29386  224.00603 ]\n",
       " [376.34207  282.3346   660.26355  518.43146 ]\n",
       " [ 78.94175  195.10974   91.47288  225.88666 ]\n",
       " [289.45917   90.62057  296.83038  109.50909 ]\n",
       " [376.34207  282.3346   660.26355  518.43146 ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]\n",
       " [ -1.        -1.        -1.        -1.      ]]\n",
       "<NDArray 100x4 @cpu(0)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_boxes.reshape(100,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keys': [1, 0, 2, 3]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[minx, miny, maxx, maxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(a, b, epsilon=1e-5):\n",
    "    \"\"\" Given two boxes `a` and `b` defined as a list of four numbers:\n",
    "            [x1,y1,x2,y2]\n",
    "        where:\n",
    "            x1,y1 represent the upper left corner\n",
    "            x2,y2 represent the lower right corner\n",
    "        It returns the Intersect of Union score for these two boxes.\n",
    "\n",
    "    Args:\n",
    "        a:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        b:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        epsilon:    (float) Small value to prevent division by zero\n",
    "\n",
    "    Returns:\n",
    "        (float) The Intersect of Union score.\n",
    "    \"\"\"\n",
    "    # COORDINATES OF THE INTERSECTION BOX\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "\n",
    "    # AREA OF OVERLAP - Area where the boxes intersect\n",
    "    width = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "    # handle case where there is NO overlap\n",
    "    if (width<0) or (height <0):\n",
    "        return 0.0\n",
    "    area_overlap = width * height\n",
    "\n",
    "    # COMBINED AREA\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "\n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = area_overlap / (area_combined+epsilon)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>coco_url</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flickr_url</th>\n",
       "      <th>height</th>\n",
       "      <th>license</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>31935.48505</td>\n",
       "      <td>[279.11, 209.81, 206.02, 160.44]</td>\n",
       "      <td>72</td>\n",
       "      <td>29131</td>\n",
       "      <td>464476</td>\n",
       "      <td>0</td>\n",
       "      <td>[[279.11, 370.25, 281.96, 214.56, 283.86, 209....</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000046...</td>\n",
       "      <td>2013-11-14 18:23:40</td>\n",
       "      <td>000000464476.jpg</td>\n",
       "      <td>http://farm1.staticflickr.com/24/35275654_7d93...</td>\n",
       "      <td>375</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>22237.67500</td>\n",
       "      <td>[281.13, 40.81, 165.48, 166.35]</td>\n",
       "      <td>72</td>\n",
       "      <td>1624484</td>\n",
       "      <td>464476</td>\n",
       "      <td>0</td>\n",
       "      <td>[[283.29, 44.28, 288.06, 40.81, 441.84, 41.68,...</td>\n",
       "      <td>http://images.cocodataset.org/val2017/00000046...</td>\n",
       "      <td>2013-11-14 18:23:40</td>\n",
       "      <td>000000464476.jpg</td>\n",
       "      <td>http://farm1.staticflickr.com/24/35275654_7d93...</td>\n",
       "      <td>375</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             area                              bbox  category_id       id  \\\n",
       "48    31935.48505  [279.11, 209.81, 206.02, 160.44]           72    29131   \n",
       "2863  22237.67500   [281.13, 40.81, 165.48, 166.35]           72  1624484   \n",
       "\n",
       "      image_id  iscrowd                                       segmentation  \\\n",
       "48      464476        0  [[279.11, 370.25, 281.96, 214.56, 283.86, 209....   \n",
       "2863    464476        0  [[283.29, 44.28, 288.06, 40.81, 441.84, 41.68,...   \n",
       "\n",
       "                                               coco_url        date_captured  \\\n",
       "48    http://images.cocodataset.org/val2017/00000046...  2013-11-14 18:23:40   \n",
       "2863  http://images.cocodataset.org/val2017/00000046...  2013-11-14 18:23:40   \n",
       "\n",
       "             file_name                                         flickr_url  \\\n",
       "48    000000464476.jpg  http://farm1.staticflickr.com/24/35275654_7d93...   \n",
       "2863  000000464476.jpg  http://farm1.staticflickr.com/24/35275654_7d93...   \n",
       "\n",
       "      height  license  width  \n",
       "48       375        3    500  \n",
       "2863     375        3    500  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b9a19488f020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m##gt_labels = np.array(labels['category_id'].apply(np.array))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmap_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mcoco_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gluoncv/utils/metrics/voc_detection.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, pred_bboxes, pred_labels, pred_scores, gt_bboxes, gt_labels, gt_difficults)\u001b[0m\n\u001b[1;32m    105\u001b[0m         for pred_bbox, pred_label, pred_score, gt_bbox, gt_label, gt_difficult in zip(\n\u001b[1;32m    106\u001b[0m                 *[as_numpy(x) for x in [pred_bboxes, pred_labels, pred_scores,\n\u001b[0;32m--> 107\u001b[0;31m                                         gt_bboxes, gt_labels, gt_difficults]]):\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;31m# strip padding -1 for pred and gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gluoncv/utils/metrics/voc_detection.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         for pred_bbox, pred_label, pred_score, gt_bbox, gt_label, gt_difficult in zip(\n\u001b[0;32m--> 106\u001b[0;31m                 *[as_numpy(x) for x in [pred_bboxes, pred_labels, pred_scores,\n\u001b[0m\u001b[1;32m    107\u001b[0m                                         gt_bboxes, gt_labels, gt_difficults]]):\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# strip padding -1 for pred and gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gluoncv/utils/metrics/voc_detection.py\u001b[0m in \u001b[0;36mas_numpy\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "coco_metric.reset()\n",
    "\n",
    "#results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_2/'\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "#baseline_model = baseline.BaselineClassifier(model='faster_rcnn_resnet101_v1d_coco')\n",
    "baseline_model = baseline.BaselineClassifier(model='yolo3_darknet53_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "    #image_id = int(image[:-4])\n",
    "    #labels = val_electronics[val_electronics['image_id']==image_id]\n",
    "    #gt_bboxes = np.array([[coord for coord in entry] for entry in labels['bbox']]).reshape(1,len(labels),4)\n",
    "    ##gt_bboxes = np.array(labels['bbox'].apply(np.array))\n",
    "    #gt_labels = np.array([entry for entry in labels['category_id']]).reshape(1,len(labels))\n",
    "    ##gt_labels = np.array(labels['category_id'].apply(np.array))\n",
    "    \n",
    "    #map_object.update(bounding_boxes, class_ids.reshape(1,100), scores.reshape(1,100), gt_bboxes, gt_labels)\n",
    "    coco_metric.update(bounding_boxes, class_ids, scores)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.92s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['~~~~ Summary metrics ~~~~\\n',\n",
       "  'person',\n",
       "  'bicycle',\n",
       "  'car',\n",
       "  'motorcycle',\n",
       "  'airplane',\n",
       "  'bus',\n",
       "  'train',\n",
       "  'truck',\n",
       "  'boat',\n",
       "  'traffic light',\n",
       "  'fire hydrant',\n",
       "  'stop sign',\n",
       "  'parking meter',\n",
       "  'bench',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'dog',\n",
       "  'horse',\n",
       "  'sheep',\n",
       "  'cow',\n",
       "  'elephant',\n",
       "  'bear',\n",
       "  'zebra',\n",
       "  'giraffe',\n",
       "  'backpack',\n",
       "  'umbrella',\n",
       "  'handbag',\n",
       "  'tie',\n",
       "  'suitcase',\n",
       "  'frisbee',\n",
       "  'skis',\n",
       "  'snowboard',\n",
       "  'sports ball',\n",
       "  'kite',\n",
       "  'baseball bat',\n",
       "  'baseball glove',\n",
       "  'skateboard',\n",
       "  'surfboard',\n",
       "  'tennis racket',\n",
       "  'bottle',\n",
       "  'wine glass',\n",
       "  'cup',\n",
       "  'fork',\n",
       "  'knife',\n",
       "  'spoon',\n",
       "  'bowl',\n",
       "  'banana',\n",
       "  'apple',\n",
       "  'sandwich',\n",
       "  'orange',\n",
       "  'broccoli',\n",
       "  'carrot',\n",
       "  'hot dog',\n",
       "  'pizza',\n",
       "  'donut',\n",
       "  'cake',\n",
       "  'chair',\n",
       "  'couch',\n",
       "  'potted plant',\n",
       "  'bed',\n",
       "  'dining table',\n",
       "  'toilet',\n",
       "  'tv',\n",
       "  'laptop',\n",
       "  'mouse',\n",
       "  'remote',\n",
       "  'keyboard',\n",
       "  'cell phone',\n",
       "  'microwave',\n",
       "  'oven',\n",
       "  'toaster',\n",
       "  'sink',\n",
       "  'refrigerator',\n",
       "  'book',\n",
       "  'clock',\n",
       "  'vase',\n",
       "  'scissors',\n",
       "  'teddy bear',\n",
       "  'hair drier',\n",
       "  'toothbrush',\n",
       "  '~~~~ MeanAP @ IoU=[0.50,0.95] ~~~~\\n'],\n",
       " ['Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0',\n",
       "  '0.0'])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map_object.get()\n",
    "coco_metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884.2778913974762"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>scores</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927936</td>\n",
       "      <td>70.859024</td>\n",
       "      <td>81.128845</td>\n",
       "      <td>162.252640</td>\n",
       "      <td>329.081268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>376.342072</td>\n",
       "      <td>282.334595</td>\n",
       "      <td>660.263550</td>\n",
       "      <td>518.431458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.356848</td>\n",
       "      <td>376.498962</td>\n",
       "      <td>289.023132</td>\n",
       "      <td>657.539246</td>\n",
       "      <td>509.743530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.326432</td>\n",
       "      <td>194.305130</td>\n",
       "      <td>31.842560</td>\n",
       "      <td>372.927612</td>\n",
       "      <td>205.119370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.145672</td>\n",
       "      <td>194.305130</td>\n",
       "      <td>31.842560</td>\n",
       "      <td>372.927612</td>\n",
       "      <td>205.119370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  class_id    scores           1           2           3  \\\n",
       "0  000000464476       0.0  0.927936   70.859024   81.128845  162.252640   \n",
       "1  000000464476      63.0  0.692063  376.342072  282.334595  660.263550   \n",
       "2  000000464476      62.0  0.356848  376.498962  289.023132  657.539246   \n",
       "3  000000464476       7.0  0.326432  194.305130   31.842560  372.927612   \n",
       "4  000000464476       6.0  0.145672  194.305130   31.842560  372.927612   \n",
       "\n",
       "            4  \n",
       "0  329.081268  \n",
       "1  518.431458  \n",
       "2  509.743530  \n",
       "3  205.119370  \n",
       "4  205.119370  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_test_annotations.to_csv('val_result_annotations_2.csv')\n",
    "all_test_annotations.to_csv('val_result_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = []#[0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies = []#[0, 0, 0, 0, 0, 0]\n",
    "#detection_accuracies_by_class = []\n",
    "num_labels_detected = []\n",
    "num_labels = []\n",
    "unique_labels_by_image = []\n",
    "unique_preds_by_image = []\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    current_unique_preds = [0, 0, 0, 0, 0, 0]\n",
    "    current_unique_labels = [0, 0, 0, 0, 0, 0]\n",
    "    pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "    label_counts = [0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    unique_label_count = len(unique_labels)\n",
    "    unique_labels_detected = 0\n",
    "    for label in unique_labels:\n",
    "        #label_counts[label-72] += 1\n",
    "        current_unique_labels[label-72] += 1\n",
    "        if label in unique_preds:\n",
    "            unique_labels_detected += 1\n",
    "    for pred in unique_preds:\n",
    "        #pred_counts[pred-72] += 1\n",
    "        current_unique_preds[pred-72] += 1\n",
    "    \n",
    "    #new method: count instances of each id to take FP into account\n",
    "    \n",
    "    #new method: tally accuracy for each image separately\n",
    "    \n",
    "    #store counts of each label and pred for each image\n",
    "    total_pred_counts.append(pred_counts)\n",
    "    total_label_counts.append(label_counts)\n",
    "    \n",
    "    #store unique labels and preds\n",
    "    unique_labels_by_image.append(current_unique_labels)\n",
    "    unique_preds_by_image.append(current_unique_preds)\n",
    "    \n",
    "    #counts of unique labels and preds\n",
    "    num_labels.append(unique_label_count)\n",
    "    num_labels_detected.append(unique_labels_detected)\n",
    "    \n",
    "    #detection_accuracies.append(num_labels_detected/num_labels)\n",
    "    #detection_accuracies_by_class.append(list(np.divide(current_pred_counts, current_label_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.DataFrame(total_pred_counts)\n",
    "label_counts = pd.DataFrame(total_label_counts)\n",
    "pred_counts[6] = pred_counts.sum(axis=1)\n",
    "label_counts[6] = label_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6\n",
       "0  1  0  0  0  0  0  1\n",
       "1  1  0  0  0  0  0  1\n",
       "2  1  0  0  0  0  0  1\n",
       "3  1  0  0  0  0  0  1\n",
       "4  2  0  0  0  1  0  3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.431579\n",
       "1    0.366071\n",
       "2    0.314286\n",
       "3    0.709091\n",
       "4    0.543624\n",
       "5    0.630522\n",
       "6    0.476301\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = label_counts.subtract(pred_counts).abs()\n",
    "error_rate_by_class = errors.sum(axis=0).divide(label_counts.sum(axis=0))\n",
    "error_rate_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.52\n",
       "1    0.50\n",
       "2    0.00\n",
       "3    0.00\n",
       "4    0.25\n",
       "5    0.50\n",
       "6    0.40\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1. , 0. , 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. , 0. , 1. ,\n",
       "       1. , 0. , 0. , 0. , 0. , 1. , 1. , 1. , 0. , 1. , 1. ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.divide(num_labels_detected, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5712962962962963"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average percentage of unique electronics labels identified in a picture\n",
    "np.mean(np.divide(num_labels_detected, num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "576"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images = len(num_labels)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    141\n",
       "1    124\n",
       "2     65\n",
       "3     68\n",
       "4     66\n",
       "5     88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which of the unique labels were predicted?\n",
    "unique_labels_detected = (pd.DataFrame(unique_labels_by_image).astype(bool) & pd.DataFrame(unique_preds_by_image).astype(bool)).multiply(1).astype(int)\n",
    "unique_labels_detected.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204\n",
       "1    176\n",
       "2     87\n",
       "3    138\n",
       "4    103\n",
       "5    205\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_labeled = pd.DataFrame(unique_labels_by_image).sum(axis=0)\n",
    "num_images_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6046002190580504"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overall rate of detecting that a label is present\n",
    "unique_labels_detected.sum(axis=0).sum()/num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.691176\n",
       "1    0.704545\n",
       "2    0.747126\n",
       "3    0.492754\n",
       "4    0.640777\n",
       "5    0.429268\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each class, what fraction of images containing that class are predicted to contain that class?\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176078294692929"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average rate of detecting presence of a label, by class\n",
    "unique_labels_detected.sum(axis=0).divide(num_images_labeled).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "1     3\n",
       "2     2\n",
       "3     1\n",
       "4     3\n",
       "5     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_detected = pd.DataFrame(unique_preds_by_image).sum(axis=0)\n",
    "num_images_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.647059\n",
       "1    1.500000\n",
       "2    1.000000\n",
       "3    1.000000\n",
       "4    1.000000\n",
       "5    0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(num_images_detected, num_images_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_labeled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "results_folder = '/mnt/muthderd/MIDS/W210/data/val_results_3/'\n",
    "data_folder = '/mnt/muthderd/MIDS/W210/data/val2017/'\n",
    "\n",
    "#test_filenames = os.listdir(data_folder)\n",
    "test_filenames = files_to_open#[:25]\n",
    "\n",
    "all_test_annotations = pd.DataFrame(columns=['image_id', 'class_id', 'scores', 1, 2, 3, 4])\n",
    "\n",
    "baseline_model = baseline.BaselineClassifier(model='ssd_512_resnet50_v1_coco')\n",
    "\n",
    "pred_start = time.time()\n",
    "\n",
    "for image in test_filenames:\n",
    "    class_ids, scores, bounding_boxes = baseline_model.classify_objects(image, data_folder, results_folder)\n",
    "    \n",
    "    class_id_series = pd.Series(class_ids[0].asnumpy().reshape(len(class_ids[0]),))\n",
    "    score_series = pd.Series(scores[0].asnumpy().reshape(len(scores[0]),))\n",
    "    b_box_DF = pd.DataFrame(bounding_boxes[0].asnumpy().reshape(len(bounding_boxes[0]),4), columns=[1,2,3,4])\n",
    "    \n",
    "    class_id_series[class_id_series>-1]\n",
    "    score_series[class_id_series>-1]\n",
    "    b_box_DF[class_id_series>-1]\n",
    "    \n",
    "    test_annotations = b_box_DF[class_id_series>-1]\n",
    "    test_annotations['class_id'] = class_id_series[class_id_series>-1]\n",
    "    test_annotations['scores'] = score_series[class_id_series>-1]\n",
    "    \n",
    "    test_annotations['image_id'] = [image[:-4]]*len(test_annotations)\n",
    "    test_annotations = test_annotations[['image_id', 'class_id', 'scores', 1, 2, 3, 4]]\n",
    "    \n",
    "    all_test_annotations = pd.concat([all_test_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "print(\"Total Annotations: \", str(len(all_test_annotations)))\n",
    "\n",
    "pred_end = time.time()\n",
    "pred_duration = pred_end - pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564.4249608516693"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>scores</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.994084</td>\n",
       "      <td>377.621948</td>\n",
       "      <td>288.606720</td>\n",
       "      <td>652.204346</td>\n",
       "      <td>508.373383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991716</td>\n",
       "      <td>69.142776</td>\n",
       "      <td>77.343102</td>\n",
       "      <td>159.968185</td>\n",
       "      <td>331.558929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.315119</td>\n",
       "      <td>367.770813</td>\n",
       "      <td>51.634697</td>\n",
       "      <td>624.718262</td>\n",
       "      <td>280.566498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.197120</td>\n",
       "      <td>195.155273</td>\n",
       "      <td>32.164742</td>\n",
       "      <td>373.132996</td>\n",
       "      <td>200.863678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105416</td>\n",
       "      <td>527.026184</td>\n",
       "      <td>351.558197</td>\n",
       "      <td>537.178528</td>\n",
       "      <td>362.751556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098738</td>\n",
       "      <td>520.610962</td>\n",
       "      <td>352.366943</td>\n",
       "      <td>528.946655</td>\n",
       "      <td>362.981628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096872</td>\n",
       "      <td>530.714355</td>\n",
       "      <td>351.537720</td>\n",
       "      <td>541.468994</td>\n",
       "      <td>362.626953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090418</td>\n",
       "      <td>548.727539</td>\n",
       "      <td>353.481445</td>\n",
       "      <td>557.438843</td>\n",
       "      <td>363.910278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.084859</td>\n",
       "      <td>195.168060</td>\n",
       "      <td>31.367561</td>\n",
       "      <td>373.370697</td>\n",
       "      <td>204.342865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000000464476</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.081976</td>\n",
       "      <td>363.247223</td>\n",
       "      <td>109.605972</td>\n",
       "      <td>589.127808</td>\n",
       "      <td>501.856873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  class_id    scores           1           2           3  \\\n",
       "0  000000464476      62.0  0.994084  377.621948  288.606720  652.204346   \n",
       "1  000000464476       0.0  0.991716   69.142776   77.343102  159.968185   \n",
       "2  000000464476      62.0  0.315119  367.770813   51.634697  624.718262   \n",
       "3  000000464476       6.0  0.197120  195.155273   32.164742  373.132996   \n",
       "4  000000464476       0.0  0.105416  527.026184  351.558197  537.178528   \n",
       "5  000000464476       0.0  0.098738  520.610962  352.366943  528.946655   \n",
       "6  000000464476       0.0  0.096872  530.714355  351.537720  541.468994   \n",
       "7  000000464476       0.0  0.090418  548.727539  353.481445  557.438843   \n",
       "8  000000464476      62.0  0.084859  195.168060   31.367561  373.370697   \n",
       "9  000000464476      62.0  0.081976  363.247223  109.605972  589.127808   \n",
       "\n",
       "            4  \n",
       "0  508.373383  \n",
       "1  331.558929  \n",
       "2  280.566498  \n",
       "3  200.863678  \n",
       "4  362.751556  \n",
       "5  362.981628  \n",
       "6  362.626953  \n",
       "7  363.910278  \n",
       "8  204.342865  \n",
       "9  501.856873  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_annotations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_annotations.to_csv('val_result_annotations_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_prob_threshold = 0.5\n",
    "result_annotations = all_test_annotations[all_test_annotations['scores']>pred_prob_threshold]\n",
    "eIDs_in_results = result_annotations.groupby('image_id')['class_id'].apply(list).to_dict()\n",
    "#eIDs_in_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick hack to deal with the fact that the class IDs predicted by the baseline model are 10 lower than those in the annotation file\n",
    "#and to throw out non electronics identified\n",
    "predicted_eIDs = {}\n",
    "for image_id in eIDs_in_results.keys():\n",
    "    corrected_IDs = np.add(eIDs_in_results[image_id],10).astype(int)\n",
    "    llimit = corrected_IDs >= 72\n",
    "    ulimit = corrected_IDs <=77\n",
    "    #print(llimit & ulimit)\n",
    "    corrected_IDs = corrected_IDs[llimit & ulimit]\n",
    "    #eIDs_in_results[image_id] = list(corrected_IDs)\n",
    "    predicted_eIDs[int(image_id)] = list(corrected_IDs)\n",
    "#predicted_eIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "total_label_counts = [0, 0, 0, 0, 0, 0]\n",
    "pred_counts = [0, 0, 0, 0, 0, 0]#can use a smarter structure here\n",
    "label_counts = [0, 0, 0, 0, 0, 0]\n",
    "#current counting method will not take into account false positives\n",
    "for image_id in predicted_eIDs.keys():\n",
    "    labels = eIDs_in_images[image_id]\n",
    "    for label in labels:\n",
    "        total_label_counts[label-72] += 1\n",
    "    preds = predicted_eIDs[image_id]\n",
    "    for pred in preds:\n",
    "        total_pred_counts[pred-72] += 1\n",
    "    \n",
    "    unique_labels = list(set(labels))\n",
    "    unique_preds = list(set(preds))\n",
    "    for label in unique_labels:\n",
    "        label_counts[label-72] += 1\n",
    "    for pred in unique_preds:\n",
    "        pred_counts[pred-72] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[212, 190, 76, 90, 98, 113]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[288, 230, 106, 282, 153, 259]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73611111, 0.82608696, 0.71698113, 0.31914894, 0.64052288,\n",
       "       0.43629344])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(total_pred_counts, total_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[172, 156, 62, 62, 78, 96]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[207, 182, 88, 144, 106, 211]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83091787, 0.85714286, 0.70454545, 0.43055556, 0.73584906,\n",
       "       0.4549763 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(pred_counts, label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6673773987206824"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_counts)/sum(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
